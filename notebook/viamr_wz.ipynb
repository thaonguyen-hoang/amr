{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11510141,"sourceType":"datasetVersion","datasetId":6707467}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# text-to-AMR","metadata":{}},{"cell_type":"code","source":"!pip install -q -U google-genai\n!pip install smatch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:51:54.294838Z","iopub.execute_input":"2025-04-22T06:51:54.295254Z","iopub.status.idle":"2025-04-22T06:52:09.038004Z","shell.execute_reply.started":"2025-04-22T06:51:54.295194Z","shell.execute_reply":"2025-04-22T06:52:09.036870Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.7/159.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting smatch\n  Downloading smatch-1.0.4.tar.gz (26 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: smatch\n  Building wheel for smatch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for smatch: filename=smatch-1.0.4-py3-none-any.whl size=24135 sha256=b17c0ac4255febd0342410c1bc4c7a69905fdeb8a92f46536ee238dd1aea7837\n  Stored in directory: /root/.cache/pip/wheels/2a/5e/2d/61b88bc74b337fbf3e998b9aa6b43bec72227e18a84a8335e8\nSuccessfully built smatch\nInstalling collected packages: smatch\nSuccessfully installed smatch-1.0.4\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from google import genai\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\nclient = genai.Client(api_key=api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:52:13.280820Z","iopub.execute_input":"2025-04-22T06:52:13.281138Z","iopub.status.idle":"2025-04-22T06:52:14.840257Z","shell.execute_reply.started":"2025-04-22T06:52:13.281110Z","shell.execute_reply":"2025-04-22T06:52:14.839503Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# def few_shot_prompt(sent):\n#     prompt = f\"\"\"\n#     Translate the given sentence into AMR graph and give no more explanation. Below are some examples:\n#     Sentence: #::snt cứ mỗi năm hành tinh này lại quay nhanh hơn , thế mà điều lệnh không thay đổi !\n#     Graph:\n#     (c / contrast\n#     :ARG1(q / quay\n#         :frequency(n / năm)\n#         :theme(h / hành tinh\n#             :mod(n1 / này))\n#         :manner(n2 / nhanh\n#             :degree(h1 / hơn)))\n#     :ARG2(t1 / thay đổi\n#         :theme(đ / điều lệnh)\n#         :polarity(wz1 / -)))\n\n#     Sentence: #::snt - thế thì sao ? ông hoàng nhỏ hỏi .\n#     Graph:\n#     (h / hỏi\n#     :agent(ô / ông hoàng\n#         :mod(n / nhỏ))\n#     :topic(a / amr-unknown\n#         :domain(t / thế)\n#         :mode interrogative(wz1 / -)))\n\n#     Sentence: #::snt mỗi phút ta phải thắp đèn và phải tắt đèn một lần !\n#     Graph:\n#     (o / obligate-01\n#     :agent(t / ta)\n#     :frequency(r / rate-entity-91\n#         :ARG2(t1 / temporal-quantity\n#             :unit(p / phút)\n#             :quant(wz1 / 1)))\n#     :theme(a / and\n#         :op1(t2 / thắp\n#             :patient(đ / đèn)\n#             :agent(wz2 / t))\n#         :op2(t3 / tắt\n#             :agent(wz3 / t)\n#             :patient(wz4 / đ))))\n\n#     Sentence: {sent}\n#     Graph:\n#     \"\"\"\n#     return prompt\n\n# def get_answer(sent):\n#     response = client.models.generate_content(model='gemini-2.0-flash',\n#                                               contents=[few_shot_prompt(sent)])\n#     return response.text.strip()\n\n# def smatch_score(prediction, target):\n#     try:\n#         match_num, test_num, gold_num = smatch.get_amr_match(prediction, target)\n#     except:\n#         return -1, -1, -1\n#     else:\n#         precision, recall, f_score = smatch.compute_f(match_num, test_num, gold_num)\n#         return precision, recall, f_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# file = '/kaggle/input/amr-lda-01/viamr.txt'\n# pairs = []\n# with open(file, encoding='utf8') as f:\n#     data = f.read().split('\\n\\n')\n#     for sample in data:\n#         idx = sample.find('\\n')\n#         if idx != -1:\n#             pair = {'sent': sample[:idx],\n#                     'amr': sample[idx:].strip()}\n#             pairs.append(pair)\n#         else:\n#             continue","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import smatch\n# import time\n# from tqdm import tqdm\n\n# def evaluate():\n#     with open('output.txt', 'w', encoding='utf-8') as f:\n#         for pair in tqdm(pairs, total=len(pairs)):\n#             sent = pair['sent']\n#             graph = pair['amr']\n        \n#             model_answer = get_answer(sent)\n#             time.sleep(5)\n#             precision, recall, f_score = smatch_score(model_answer, graph)\n\n#             f.write(sent + '\\n')\n#             f.write(model_answer + '\\n\\n')\n            \n#             if precision == recall == f_score == -1:    \n#                 continue\n                \n#             pair['predict'] = model_answer\n#             pair['f-score'] = f_score\n#             print(f'gold AMR: \\n {graph}')\n#             print(f'parsed AMR: \\n {model_answer}')\n#             print(f'f-score: {f_score} \\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluate()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# try:\n    # doc_smatch = smatch.score_amr_pairs(file, '/kaggle/working/output.txt')\n# except:\n    # print('error processing')\n# else:\n    # print(doc_smatch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AMR-LDA","metadata":{}},{"cell_type":"markdown","source":"## preprocessing","metadata":{}},{"cell_type":"markdown","source":"### replace space with underscore","metadata":{}},{"cell_type":"code","source":"# import os\n\n# base_dir = '/kaggle/input/amr-lda-01/viamr/final'\n# paths = [base_dir + '/' + fn for fn in os.listdir(base_dir)]\n# paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T07:05:38.286488Z","iopub.execute_input":"2025-04-04T07:05:38.286813Z","iopub.status.idle":"2025-04-04T07:05:38.301014Z","shell.execute_reply.started":"2025-04-04T07:05:38.286785Z","shell.execute_reply":"2025-04-04T07:05:38.299836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # check if two files are identical\n# f1 = open(paths[0], \"r\") \n# f2 = open(paths[2], \"r\") \n\n# f1_data = f1.readlines()\n# f2_data = f2.readlines()\n\n# for i in range(len(f1_data)):\n#     if f1_data[i] == f2_data[i]:\n#         continue\n#     else:\n#         print(\"Line \", i, \":\")\n#         print(\"\\tFile 1:\", f1_data[i], end='')\n#         print(\"\\tFile 2:\", f2_data[i], end='')\n\n# # closing files\n# f1.close()\t\t\t\t\t\t\t\t\t \n# f2.close()\t\t\t\t\t\t\t\t ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# texts = []\n# graphs = []\n# path = '/kaggle/input/amr-lda-01/user9_v3_1.txt'\n# fn = path.split('/')[-1][:-4]\n# with open(path, encoding='utf8') as f:\n#     data = f.read().split('\\n\\n')\n#     for sample in data[:-1]:\n#         idx = sample.find('\\n')\n#         texts.append(sample[:idx])\n#         graphs.append(sample[idx:].strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T07:07:28.830029Z","iopub.execute_input":"2025-04-04T07:07:28.830389Z","iopub.status.idle":"2025-04-04T07:07:28.864104Z","shell.execute_reply.started":"2025-04-04T07:07:28.830362Z","shell.execute_reply":"2025-04-04T07:07:28.862543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def get_prompt(graph):\n#     prompt = f\"\"\"\n#     Replace blank space with underscore (_) in each instance of the AMR graph and keep everything else the same. Here is an example:\n#     Original:\n#     (b / bi kịch\n#         :domain(c / chỗ\n#             :mod(đ / đó)))\n\n#     Result:\n#     (b / bi_kịch\n#         :domain(c / chỗ\n#             :mod(đ / đó)))\n\n#     Original: {graph}\n#     Result:\n#     \"\"\"\n#     return prompt\n\n# def connect_words(graph):\n#     response = client.models.generate_content(model='gemini-2.0-flash',\n#                                               contents=[get_prompt(graph)])\n#     return response.text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T16:36:40.268724Z","iopub.execute_input":"2025-03-30T16:36:40.269010Z","iopub.status.idle":"2025-03-30T16:36:40.273610Z","shell.execute_reply.started":"2025-03-30T16:36:40.268990Z","shell.execute_reply":"2025-03-30T16:36:40.272629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import time\n\n# def preprocess(graphs, output_file):\n#     with open(output_file, 'x', encoding='utf-8') as f:\n#         for graph in graphs:\n#             result = connect_words(graph)\n#             time.sleep(5)\n#             f.write(result + '\\n\\n')\n    \n#             # print(graph + '\\n')\n#             # print(result + '\\n\\n')\n#             # new_graphs.append(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T16:36:51.253905Z","iopub.execute_input":"2025-03-30T16:36:51.254249Z","iopub.status.idle":"2025-03-30T16:36:51.258302Z","shell.execute_reply.started":"2025-03-30T16:36:51.254220Z","shell.execute_reply":"2025-03-30T16:36:51.257617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# new_graphs = preprocess(graphs, f'graphs_{fn}.txt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## read data","metadata":{}},{"cell_type":"code","source":"# import os\n\n# original_dir = '/kaggle/input/amr-lda-01/viamr/original'\n# preprocess_dir = '/kaggle/input/amr-lda-01/viamr/preprocess'\n\n# original_files = os.listdir(original_dir)\n# preprocess_files = os.listdir(preprocess_dir)\n\n# fn = original_files[1]\n# path1 = original_dir + '/' + fn\n# path2 = preprocess_dir + f'/graphs_{fn}'\n# print(fn)\n# print(os.path.exists(path1))\n# print(os.path.exists(path2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # one file\n# texts = []\n# graphs = []\n# with open(path1, encoding='utf8') as f1:\n#     with open(path2, encoding='utf-8') as f2:\n#         data1 = f1.read().split('\\n\\n')\n#         data2 = f2.read().split('\\n\\n')\n#         assert len(data1) == len(data2)\n#         for i in range(len(data1)):\n#             idx = data1[i].find('\\n')\n#             texts.append(data1[i][:idx])\n#             graphs.append(data2[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:02:32.447410Z","iopub.execute_input":"2025-04-04T04:02:32.447747Z","iopub.status.idle":"2025-04-04T04:02:32.463198Z","shell.execute_reply.started":"2025-04-04T04:02:32.447721Z","shell.execute_reply":"2025-04-04T04:02:32.462006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nbase_dir = '/kaggle/input/amr-lda-01/viamr/reformat'\npaths = [base_dir + '/' + fn for fn in os.listdir(base_dir)]\npaths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:45:54.753108Z","iopub.execute_input":"2025-04-22T06:45:54.753426Z","iopub.status.idle":"2025-04-22T06:45:54.764973Z","shell.execute_reply.started":"2025-04-22T06:45:54.753401Z","shell.execute_reply":"2025-04-22T06:45:54.764198Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/amr-lda-01/viamr/reformat/reformat_user10_v3__user9_v2.txt',\n '/kaggle/input/amr-lda-01/viamr/reformat/reformat_user9_v3_1.txt',\n '/kaggle/input/amr-lda-01/viamr/reformat/reformat_user8_v3.txt',\n '/kaggle/input/amr-lda-01/viamr/reformat/reformat_user11_v3.txt',\n '/kaggle/input/amr-lda-01/viamr/reformat/reformat_user10_v3__user8_v2.txt']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# total\ntexts = []\ngraphs = []\nfor path in paths:\n    with open(path, encoding='utf8') as f:\n        data = f.read().split('\\n\\n')\n        for sample in data[:]:\n            idx = sample.find('\\n')\n            texts.append(sample[:idx])\n            graphs.append(sample[idx:].strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:46:01.562111Z","iopub.execute_input":"2025-04-22T06:46:01.562424Z","iopub.status.idle":"2025-04-22T06:46:01.586832Z","shell.execute_reply.started":"2025-04-22T06:46:01.562399Z","shell.execute_reply":"2025-04-22T06:46:01.586048Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"len(graphs)\nlen(texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:46:04.058617Z","iopub.execute_input":"2025-04-22T06:46:04.058875Z","iopub.status.idle":"2025-04-22T06:46:04.063506Z","shell.execute_reply.started":"2025-04-22T06:46:04.058854Z","shell.execute_reply":"2025-04-22T06:46:04.062848Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1522"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import random\ni = random.randint(0, len(texts))\nprint(texts[i])\nprint(graphs[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:46:06.901845Z","iopub.execute_input":"2025-04-22T06:46:06.902135Z","iopub.status.idle":"2025-04-22T06:46:06.907159Z","shell.execute_reply.started":"2025-04-22T06:46:06.902112Z","shell.execute_reply":"2025-04-22T06:46:06.906458Z"}},"outputs":[{"name":"stdout","text":"#::snt vì thế , tớ hơi chán .\n(c / chán\n    :pivot(t / tớ)\n    :degree(h / hơi))\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## contraposition","metadata":{}},{"cell_type":"code","source":"!pip install penman\n# !unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:46:15.225236Z","iopub.execute_input":"2025-04-22T06:46:15.225520Z","iopub.status.idle":"2025-04-22T06:46:19.601378Z","shell.execute_reply.started":"2025-04-22T06:46:15.225489Z","shell.execute_reply":"2025-04-22T06:46:19.600368Z"}},"outputs":[{"name":"stdout","text":"Collecting penman\n  Downloading penman-1.3.1-py3-none-any.whl.metadata (7.7 kB)\nDownloading penman-1.3.1-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: penman\nSuccessfully installed penman-1.3.1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import penman\nimport copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:46:19.602423Z","iopub.execute_input":"2025-04-22T06:46:19.602653Z","iopub.status.idle":"2025-04-22T06:46:19.618400Z","shell.execute_reply.started":"2025-04-22T06:46:19.602633Z","shell.execute_reply":"2025-04-22T06:46:19.617791Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def has_polarity_negative(g, z1):\n    for inst in g.instances():\n        if inst.target != '-':\n            continue\n        if (z1, ':polarity', inst.source) in g.triples:\n            z1_neg = penman.Triple(z1, ':polarity', inst.source)\n            return z1_neg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:03.103939Z","iopub.execute_input":"2025-04-22T06:47:03.104248Z","iopub.status.idle":"2025-04-22T06:47:03.108655Z","shell.execute_reply.started":"2025-04-22T06:47:03.104221Z","shell.execute_reply":"2025-04-22T06:47:03.107807Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def swappable_conditions_contraposition(g):\n    for inst in g.instances():\n        if (inst.target == 'have-condition-91'  ## this if is working for contraposition law\n         and len(g.edges(source=inst.source, role=':ARG1')) == 1\n         and len(g.edges(source=inst.source, role=':ARG2')) == 1):\n            return inst.source","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:04.434114Z","iopub.execute_input":"2025-04-22T06:47:04.434424Z","iopub.status.idle":"2025-04-22T06:47:04.439224Z","shell.execute_reply.started":"2025-04-22T06:47:04.434402Z","shell.execute_reply":"2025-04-22T06:47:04.438101Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def swappable_conditions_contraposition_2(g):\n    for inst in g.instances():\n        if (len(g.edges(source=inst.source, role=':condition')) == 1):\n            return inst.source","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:09.791313Z","iopub.execute_input":"2025-04-22T06:47:09.791606Z","iopub.status.idle":"2025-04-22T06:47:09.795676Z","shell.execute_reply.started":"2025-04-22T06:47:09.791585Z","shell.execute_reply":"2025-04-22T06:47:09.794624Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def contraposition(graphs, texts):\n    return_list = []\n    label_list = []\n    sentence_list = []\n    graph_list = []\n    if graphs is None:\n        return\n    for index, graph in enumerate(graphs):\n        if graph is None:\n            continue\n        try:\n            g = penman.decode(graph)\n        except:\n            continue\n        else:\n            z0 = swappable_conditions_contraposition_2(g)\n            if z0 is None:\n                continue\n            negative_sample_g = copy.deepcopy(g)\n            z1 = g.edges(source=z0, role=':condition')[0].target\n            z1_neg = has_polarity_negative(g, z1)\n            z0_neg = has_polarity_negative(g, z0)\n            \n            # add negative polarity to both clauses\n            if z1_neg is None and z0_neg is None:\n                wzs = len([wz for wz in g.variables() if 'wz' in wz])\n                g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n                g.triples.append((z1, ':polarity', f'wz{wzs+1}'))\n                g.triples.append((f'wz{wzs+2}', ':instance', '-'))\n                g.triples.append((z0, ':polarity', f'wz{wzs+2}'))\n                # negative sample\n                # negative_sample_g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n                # negative_sample_g.triples.append((z0, ':polarity', f'wz{wzs+1}'))\n            elif z1_neg is not None and z0_neg is not None:\n                g.triples.remove((z1_neg.target, ':instance', '-'))\n                g.triples.remove(z1_neg)\n                g.triples.remove((z0_neg.target, ':instance', '-'))\n                g.triples.remove(z0_neg)\n                # negative sample\n                # negative_sample_g.triples.remove((z0_neg.target, ':instance', '-'))\n                # negative_sample_g.triples.remove(z0_neg)\n            elif z1_neg is None and z0_neg is not None:\n                g.triples.remove((z0_neg.target, ':instance', '-'))\n                g.triples.remove(z0_neg)\n                wzs = len([wz for wz in g.variables() if 'wz' in wz])\n                g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n                g.triples.append((z1, ':polarity', f'wz{wzs+1}'))\n                # negative sample\n                # negative_sample_g.triples.remove((z0_neg.target, ':instance', '-'))\n                # negative_sample_g.triples.remove(z0_neg)\n            elif z1_neg is not None and z0_neg is None:\n                g.triples.remove((z1_neg.target, ':instance', '-'))\n                g.triples.remove(z1_neg)\n                wzs = len([wz for wz in g.variables() if 'wz' in wz])\n                g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n                g.triples.append((z0, ':polarity', f'wz{wzs+1}'))\n                # negative sample\n                # negative_sample_g.triples.remove((z1_neg.target, ':instance', '-'))\n                # negative_sample_g.triples.remove(z1_neg)\n\n            # switch condition\n            g.triples.remove((z0, ':condition', z1))\n            g.triples.append((z1, ':condition', z0))\n            # g.metadata = {}\n            # g.epidata = {}\n            # print(g)\n\n            # new_triples = []\n            # for triple in g.triples:\n            #     subj, role, obj = triple\n            \n            #     # Replace subject or object if it matches old ID\n            #     subj = z0 if subj == z1 else subj\n            #     obj = z1 if obj == old_id else obj\n            \n            #     # Replace the instance triple with the new concept\n            #     if triple == (old_id, 'instance', 'boy'):\n            #         new_triples.append((new_id, 'instance', new_concept))\n            #     else:\n            #         new_triples.append((subj, role, obj))\n            \n            # # Update the graph with the new triples\n            # graph.triples = new_triples\n            \n            try:\n                new_graph = penman.encode(g, indent=3)\n            except Exception as e:\n                print(texts[index])\n                print(graph)\n                print(g)\n                print(e)\n                continue\n            else:\n                return_list.append(new_graph)\n                label_list.append(1)\n                sentence_list.append(texts[index])\n                graph_list.append(graph)\n\n            # append negative samples\n            # negative_sample_graph = penman.encode(negative_sample_g, indent=3)\n            # return_list.append(negative_sample_graph)\n            # label_list.append(0)\n            # sentence_list.append(texts[index])\n            # graph_list.append(graph)\n    return return_list, label_list, sentence_list, graph_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:10.778388Z","iopub.execute_input":"2025-04-22T06:47:10.778675Z","iopub.status.idle":"2025-04-22T06:47:10.791766Z","shell.execute_reply.started":"2025-04-22T06:47:10.778652Z","shell.execute_reply":"2025-04-22T06:47:10.790836Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## implication","metadata":{}},{"cell_type":"code","source":"def swappable_conditions_implication(g):\n    for inst in g.instances():\n        if (inst.target == 'or'   ## this elif is working for implication law\n         and len(g.edges(source=inst.source, role=':op1')) == 1\n         and len(g.edges(source=inst.source, role=':op2')) == 1\n         and len(g.edges(target=inst.source)) == 0):\n            yield inst.source","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:15.746136Z","iopub.execute_input":"2025-04-22T06:47:15.746427Z","iopub.status.idle":"2025-04-22T06:47:15.750949Z","shell.execute_reply.started":"2025-04-22T06:47:15.746399Z","shell.execute_reply":"2025-04-22T06:47:15.750014Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def implication_negative(g, z1):\n    z1_neg = has_polarity_negative(g, z1)\n    if z1_neg is None:\n        wzs = len([wz for wz in g.variables() if 'wz' in wz])\n        g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n        g.triples.append((z1, ':polarity', f'wz{wzs+1}'))\n    else:\n        g.triples.remove((z1_neg.target, ':instance', '-'))\n        g.triples.remove(z1_neg)\n    return g\n\ndef implication(graphs, texts):\n    '''A -> B = not(A) or B'''\n    return_list = []\n    label_list = []\n    sentence_list = []\n    graph_list = []\n    if graphs is None:\n        return\n    for index, graph in enumerate(graphs):\n        if graph is None:\n            continue\n        try:\n            g = penman.decode(graph)\n        except:\n            continue\n        else:\n            z0 = swappable_conditions_contraposition_2(g)\n            # negative_sample_g = copy.deepcopy(g)\n            if z0 is not None:\n                root = g.edges(target=z0)\n                if len(root) == 0:\n                    z1 = g.edges(source=z0, role=':condition')[0].target\n                    # add negative polarity\n                    g = implication_negative(g, z1)\n                \n                    # 'condition' -> 'or'\n                    os = len([wz for wz in g.variables() if wz.startswith('o')])\n                    source = 'o' if os == 0 else f'o{os}'\n                    g.triples.remove((z0, ':condition', z1))\n                    g.triples.append((source, ':instance', 'or'))\n                    g.triples.append((source, ':op1', z1))\n                    g.triples.append((source, ':op2', z0))\n    \n                    \n                    new_graph = penman.encode(g, indent=3, top=source)\n                    return_list.append(new_graph)\n                    label_list.append(1)\n                    sentence_list.append(texts[index])\n                    graph_list.append(graph)\n            else:\n                for z in swappable_conditions_implication(g):\n                    root = g.edges(target=z)\n                    if len(root) == 0:\n                        g_temp = copy.deepcopy(g)\n                        ## A or B\n                        z1 = g.edges(source=z, role=':op1')[0].target\n                        z5 = g.edges(source=z, role=':op2')[0].target\n                        \n                        # add negative polarity\n                        g = implication_negative(g, z1)\n                        \n                        # 'or' -> 'condition'\n                        # z_root = g.edges(target=z)[0]\n                        g.triples.remove((z, ':instance', 'or'))\n                        g.triples.remove((z, ':op1', z1))\n                        g.triples.remove((z, ':op2', z5))\n                        g.triples.append((z5, ':condition', z1))\n                        # if z_root is not None:\n                        #     print(graph)\n                        #     z_source = z_root.source\n                        #     z_role = z_root.role\"\n                        #     g.triples.remove(z_root)\n                        #     g.triples.append((z_source, z_role, z5))\n                        g.metadata = {}\n                        g.epidata = {}\n                        try:\n                            new_graph = penman.encode(g, top=z5, indent=3)\n                        except:\n                            # print(g)\n                            # print(graph)\n                            continue\n                        else:\n                            return_list.append(new_graph)\n                            label_list.append(1)\n                            sentence_list.append(texts[index])\n                            graph_list.append(graph)\n                        \n                        ## B or A\n                        # add negative polarity\n                        g_temp = implication_negative(g_temp, z5)\n    \n                        # 'or' -> 'condition'\n                        # z_root = g.edges(target=z)[0]\n                        g_temp.triples.remove((z, ':instance', 'or'))\n                        g_temp.triples.remove((z, ':op1', z1))\n                        g_temp.triples.remove((z, ':op2', z5))\n                        g_temp.triples.append((z1, ':condition', z5))\n                        # if z_root is not None:\n                        #     print(graph)\n                        #     z_source = z_root.source\n                        #     z_role = z_root.role\n                        #     g.triples.remove(z_root)\n                        #     g.triples.append((z_source, z_role, z1))\n                        g_temp.metadata = {}\n                        g_temp.epidata = {}\n                        try:\n                            new_graph_temp = penman.encode(g_temp, indent=3, top=z1)\n                        except:\n                            # print(g_temp)\n                            # print(graph)\n                            continue\n                        else:\n                            return_list.append(new_graph_temp)\n                            label_list.append(1)\n                            sentence_list.append(texts[index])\n                            graph_list.append(graph)\n    return return_list, label_list, sentence_list, graph_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:16.493211Z","iopub.execute_input":"2025-04-22T06:47:16.493561Z","iopub.status.idle":"2025-04-22T06:47:16.506844Z","shell.execute_reply.started":"2025-04-22T06:47:16.493528Z","shell.execute_reply":"2025-04-22T06:47:16.505885Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## commutation","metadata":{}},{"cell_type":"code","source":"def swappable_conditions_commutative(g):\n    for inst in g.instances():\n        if (inst.target == 'and'   # find sentence with 'and'\n         and len(g.edges(source=inst.source, role=':op1')) == 1 # make sure it has at least 2 clauses\n         and len(g.edges(source=inst.source, role=':op2')) == 1):\n            yield inst.source\n\ndef switch_node(g, source, relations):\n    z1 = g.edges(source=source, role=relations[0])[0].target\n    z5 = g.edges(source=source, role=relations[1])[0].target\n    g.triples.remove((source, relations[0], z1))  # remove the triples\n    g.triples.remove((source, relations[1], z5))\n    g.triples.append((source, relations[0], z5))  # add the replacements\n    g.triples.append((source, relations[1], z1))\n    return g\n\ndef commutative_negative(g, source, relations):\n    # negative_sample_g = copy.deepcopy(g)\n    z1 = g.edges(source=source, role=relations[0])[0].target\n    z5 = g.edges(source=source, role=relations[1])[0].target\n    z1_neg = has_polarity_negative(g, z1)\n    z5_neg = has_polarity_negative(g, z5)\n    \n    if z1_neg is None and z5_neg is None:\n        wzs = len([wz for wz in g.variables() if 'wz' in wz])\n        g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n        g.triples.append((z5, ':polarity', f'wz{wzs+1}'))\n    elif z5_neg is not None:\n        g.triples.remove((z5_neg.target, ':instance', '-'))\n        g.triples.remove(z5_neg)\n    elif z1_neg is not None:\n        g.triples.remove((z1_neg.target, ':instance', '-'))\n        g.triples.remove(z1_neg)\n    return g\n\ndef commutative(graphs, texts):\n    return_list = []\n    label_list = []\n    sentence_list = []\n    graph_list = []\n    if graphs is None:\n        return\n    for index, graph in enumerate(graphs):\n        if graph is None:\n            continue\n        try:\n            g = penman.decode(graph)\n        except:\n            continue\n        else:\n            sources = list(swappable_conditions_commutative(g)) + list(swappable_conditions_implication(g))\n            if len(sources) == 0:\n                continue\n            for z0 in sources:\n                negative_sample_g = copy.deepcopy(g)\n                relations = [':op1', ':op2']\n                g = switch_node(g, z0, relations)\n                new_graph = penman.encode(g, indent=3)\n                return_list.append(new_graph)\n                label_list.append(1)\n                sentence_list.append(texts[index])\n                graph_list.append(graph)\n    \n                # negative_sample_g = commutative_negative(negative_sample_g, z0, relations)\n                # negative_sample_graph = penman.encode(negative_sample_g, indent=3)\n                # return_list.append(negative_sample_graph)\n                # label_list.append(0)\n                # sentence_list.append(texts[index])\n                # graph_list.append(graph)\n\n    return return_list, label_list, sentence_list, graph_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:21.213908Z","iopub.execute_input":"2025-04-22T06:47:21.214248Z","iopub.status.idle":"2025-04-22T06:47:21.224655Z","shell.execute_reply.started":"2025-04-22T06:47:21.214216Z","shell.execute_reply":"2025-04-22T06:47:21.223765Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"contraposition_list, contraposition_label_list, contraposition_sentence_list, contraposition_graph_list = [], [], [], []\ncommutative_list, commutative_label_list, commutative_sentence_list, commutative_graph_list = [], [], [], []\nimplication_list, implication_label_list, implication_sentence_list, implication_graph_list = [], [], [], []\n\ncontraposition_list, contraposition_label_list, contraposition_sentence_list, contraposition_graph_list = contraposition(graphs, texts)\ncommutative_list, commutative_label_list, commutative_sentence_list, commutative_graph_list = commutative(graphs, texts)\nimplication_list, implication_label_list, implication_sentence_list, implication_graph_list = implication(graphs, texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:29.893303Z","iopub.execute_input":"2025-04-22T06:47:29.893611Z","iopub.status.idle":"2025-04-22T06:47:31.102085Z","shell.execute_reply.started":"2025-04-22T06:47:29.893584Z","shell.execute_reply":"2025-04-22T06:47:31.101417Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print('total: ', len(graphs))\nprint('contraposition: ', len(contraposition_list))\nprint('commutative: ', len(commutative_list))\nprint('implication: ', len(implication_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:38.888670Z","iopub.execute_input":"2025-04-22T06:47:38.888940Z","iopub.status.idle":"2025-04-22T06:47:38.894161Z","shell.execute_reply.started":"2025-04-22T06:47:38.888919Z","shell.execute_reply":"2025-04-22T06:47:38.893338Z"}},"outputs":[{"name":"stdout","text":"total:  1522\ncontraposition:  51\ncommutative:  205\nimplication:  31\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"augmented = []\nfor i in range(len(contraposition_list)):\n    augmented.append({'source': contraposition_sentence_list[i],\n                      'original_graph': contraposition_graph_list[i],\n                      'modified_graph': contraposition_list[i], \n                      'tag': 'contraposition'})\n\nfor i in range(len(commutative_list)):\n    augmented.append({'source': commutative_sentence_list[i],\n                      'original_graph': commutative_graph_list[i],\n                      'modified_graph': commutative_list[i], \n                      'tag': 'commutative'})\n\nfor i in range(len(implication_list)):\n    augmented.append({'source': implication_sentence_list[i],\n                      'original_graph': implication_graph_list[i],\n                      'modified_graph': implication_list[i], \n                      'tag': 'implication'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:47:49.284295Z","iopub.execute_input":"2025-04-22T06:47:49.284586Z","iopub.status.idle":"2025-04-22T06:47:49.290817Z","shell.execute_reply.started":"2025-04-22T06:47:49.284562Z","shell.execute_reply":"2025-04-22T06:47:49.289743Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import json\n\noutput_file = 'augmented_sent_level.json'\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(augmented, f, indent=3, ensure_ascii=False)\n    # for item in augmented:\n    #     f.write('#::tag ' + item['tag'] + '\\n')\n    #     f.write(item['source'] + '\\n')\n    #     f.write(item['original_graph'] + '\\n')\n    #     f.write(item['modified_graph'] + '\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:48:08.941965Z","iopub.execute_input":"2025-04-22T06:48:08.942344Z","iopub.status.idle":"2025-04-22T06:48:08.955040Z","shell.execute_reply.started":"2025-04-22T06:48:08.942316Z","shell.execute_reply":"2025-04-22T06:48:08.954048Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## double negation","metadata":{}},{"cell_type":"code","source":"# import nltk\n# from nltk.corpus import wordnet\n\n# def double_negation(graphs, sentence_list):\n#     return_list = []\n#     negative_list = []\n#     label_list = []\n#     sentence_and_tag_list = []\n#     return_sents = []\n#     returned_sentence_and_tag_list = []\n#     if graphs is None:\n#         return\n#     for index, graph in enumerate(graphs):\n#         if graph is None:\n#             continue\n#         g = penman.decode(graph)\n#         updated_g = copy.deepcopy(g)\n#         negative_g = copy.deepcopy(g)\n#         if \":polarity -\" not in graph:  ## We only consider the case that the sentence does not have negation.\n#             z0 = updated_g.instances()[0].source\n#             updated_g.triples.append((z0, ':polarity', '-'))\n#             temp_graph = penman.encode(updated_g)\n#             start = temp_graph.index(\"\\n\")\n#             return_list.append(temp_graph[start+1:len(temp_graph)])\n#             sentence_and_tag_list.append(sentence_list[index])\n#             negative_list.append(penman.encode(negative_g))\n\n#     if len(return_list) > 0:\n#         gtos = amrlib.load_gtos_model(\"/kaggle/input/amr-lda-01/models/generate_t5wtense\")\n#         sents, _ = gtos.generate(return_list)\n#         punctuation_string = string.punctuation\n\n#         for idx, sent in enumerate(sents):\n#             temp_sent = copy.deepcopy(sent)\n#             for i in punctuation_string:\n#                 temp_sent = temp_sent.replace(i, '')\n#             splited_sent = temp_sent.split()\n#             for stem in splited_sent:\n#                 if len(wordnet.synsets(stem)) > 0:\n#                     syn = wordnet.synsets(stem)[0]\n#                     good = wordnet.synset(syn.name())\n#                     antonym = good.lemmas()[0].antonyms()\n#                     if len(antonym) > 0:\n#                         if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n#                             sent = sent.replace(stem,antonym[0].name())\n#                             returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n#                             return_sents.append(sent)\n#                             label_list.append(1)\n#                             break\n\n#         neg_sents, _ = gtos.generate(negative_list)\n\n#         for idx, sent in enumerate(neg_sents):\n#             temp_sent = copy.deepcopy(sent)\n#             for i in punctuation_string:\n#                 temp_sent = temp_sent.replace(i, '')\n#             splited_sent = temp_sent.split()\n#             for stem in splited_sent:\n#                 if len(wordnet.synsets(stem)) > 0:\n#                     syn = wordnet.synsets(stem)[0]\n#                     good = wordnet.synset(syn.name())\n#                     antonym = good.lemmas()[0].antonyms()\n#                     if len(antonym) > 0:\n#                         if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n#                             sent = sent.replace(stem, antonym[0].name())\n#                             returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n#                             return_sents.append(sent)\n#                             label_list.append(0)\n#                             break\n\n#     return return_sents, label_list, returned_sentence_and_tag_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:01:11.772338Z","iopub.execute_input":"2025-04-04T04:01:11.773123Z","iopub.status.idle":"2025-04-04T04:01:13.385191Z","shell.execute_reply.started":"2025-04-04T04:01:11.773057Z","shell.execute_reply":"2025-04-04T04:01:13.384352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# syn = wordnet.synsets('cancel')[0]\n# syn.lemmas()[0].antonyms()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T04:06:48.607919Z","iopub.execute_input":"2025-04-04T04:06:48.608299Z","iopub.status.idle":"2025-04-04T04:06:48.616460Z","shell.execute_reply.started":"2025-04-04T04:06:48.608272Z","shell.execute_reply":"2025-04-04T04:06:48.615575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import penman\n\n# # Original AMR\n# amr_str = \"\"\"\n# (w / want-01\n#    :arg0 (b / boy)\n#    :arg1 (g / go-01\n#              :arg0 b))\n# \"\"\"\n\n# # Parse the AMR\n# graph = penman.decode(amr_str)\n\n# # Old and new node info\n# old_id = 'b'\n# new_id = 'c'\n# new_concept = 'child'\n\n# # Step 1: Update all triples where the old ID appears\n# new_triples = []\n# for triple in graph.triples:\n#     subj, role, obj = triple\n\n#     # Replace subject or object if it matches old ID\n#     subj = new_id if subj == old_id else subj\n#     obj = new_id if obj == old_id else obj\n\n#     # Replace the instance triple with the new concept\n#     if triple == (old_id, 'instance', 'boy'):\n#         new_triples.append((new_id, 'instance', new_concept))\n#     else:\n#         new_triples.append((subj, role, obj))\n\n# # Update the graph with the new triples\n# graph.triples = new_triples\n\n# # Convert back to AMR string\n# new_amr_str = penman.encode(graph, indent=6)\n# print(new_amr_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T11:41:22.293356Z","iopub.execute_input":"2025-04-15T11:41:22.293819Z","iopub.status.idle":"2025-04-15T11:41:22.304796Z","shell.execute_reply.started":"2025-04-15T11:41:22.293781Z","shell.execute_reply":"2025-04-15T11:41:22.303812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AMR-to-text","metadata":{}},{"cell_type":"code","source":"def get_prompt(graph):\n    prompt = f\"\"\"\n    ## Instruction \n    You are an Vietnamese expert linguist. Your task is to generate a sentence according to the given abstract meaning representation (AMR), \n    which is a semantic parsing of a sentence with roles and concepts.\n\n    ## Constraints \n    Follow some additional rules and notes when generating sentences: \n    - “:classifier” is used for noun classifier, which standing before a noun. \n    - “:compound” is used for compound word. \n    - “:mode” indicates type of sentence. For example: “imperative” for commands or instructions or suggestions, \n        “interrogative” or “amr-unknown ” for questions, “expressive” for sentence withexclamational words that express emotions. \n    - “:polarity -“ is used for negatives. \n    - “a / and”, “o / or”, “m / multi-sentence” indicate sentences with multiple clauses or multiple sentences that are connected. \n    - nodes with the same id refer to the same entity.\n    - the sentence should be natural and understandable. make sure to include all components of the AMR in the result sentence \n    and stick to the original words in AMR as close as possible.\n\n    ## Input\n    Graph: {graph}\n    Sentence:\n    \"\"\"\n    return prompt\n\ndef generate(graph):\n    response = client.models.generate_content(model='gemini-2.0-flash',\n                                              contents=[get_prompt(graph)])\n    return response.text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:50:32.389568Z","iopub.execute_input":"2025-04-22T06:50:32.389889Z","iopub.status.idle":"2025-04-22T06:50:32.395131Z","shell.execute_reply.started":"2025-04-22T06:50:32.389864Z","shell.execute_reply":"2025-04-22T06:50:32.394111Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\nfor item in tqdm(augmented[:5], total=len(augmented[:5])):\n    result = generate(item['modified_graph'])\n    item['gen_sent'] = result\n    time.sleep(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:52:23.771967Z","iopub.execute_input":"2025-04-22T06:52:23.772449Z","iopub.status.idle":"2025-04-22T06:52:52.489719Z","shell.execute_reply.started":"2025-04-22T06:52:23.772419Z","shell.execute_reply":"2025-04-22T06:52:52.488914Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5/5 [00:28<00:00,  5.74s/it]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"for item in augmented:\n    print(item['gen_sent'], end='\\n')\n    print(item['modified_graph'], end='\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T06:53:17.695636Z","iopub.execute_input":"2025-04-22T06:53:17.695928Z","iopub.status.idle":"2025-04-22T06:53:17.739106Z","shell.execute_reply.started":"2025-04-22T06:53:17.695905Z","shell.execute_reply":"2025-04-22T06:53:17.737962Z"}},"outputs":[{"name":"stdout","text":"Trên đời sẽ duy nhất khi cậu không cảm hoá tớ và tớ sẽ không cảm hoá cậu.\n(c3 / contrast-01\n   :ARG2 (d / duy_nhất\n      :tense (s / sẽ)\n      :time (đ / đời\n         :prep (t1 / trên))\n      :domain (wz1 / c)\n      :polarity (wz3 / -)\n      :condition-of (c1 / cảm_hoá\n         :agent (c / cậu)\n         :patient (t / tớ)\n         :polarity (wz2 / -))))\n\nTuy vậy, tớ sẽ không cảm hóa được cậu, nhưng cuộc đời tớ sẽ không nắng rực.\n(c2 / contrast-01\n   :ARG2 (r / rực\n      :domain (đ / đời\n         :poss (t1 / tớ))\n      :tense (s / sẽ)\n      :compound (n2 / nắng)\n      :polarity (wz2 / -)\n      :condition-of (c1 / cảm_hóa\n         :agent (c / cậu)\n         :patient (t / tớ)\n         :polarity (wz1 / -))))\n\nTuyệt vời! Tớ sẽ rất tiếc nếu cậu không cảm hoá được tớ.\n(t1 / tuyệt\n   :mode expressive\n   :tense (s / sẽ)\n   :degree (r / rất)\n   :polarity (wz2 / -)\n   :condition-of (c1 / cảm_hoá\n      :modality (m / một_khi)\n      :agent (c / cậu)\n      :patient (t2 / tớ)\n      :polarity (wz1 / -)))\n\nCáo nói là C đừng có đi cảm hoá tớ, và cậu đừng không vui lòng.\n(n1 / nói\n   :topic (c1 / cảm_hoá\n      :mode imperative\n      :patient (t / tớ)\n      :modality (đ / đi)\n      :agent (wz1 / c)\n      :polarity (wz3 / -)\n      :condition-of (v / vui_lòng\n         :domain (c / cậu)\n         :polarity (wz2 / -)))\n   :agent (c2 / cáo))\n\nC. đừng làm tớ cảm hoá nếu cậu không muốn cậu có một người bạn.\n(c2 / cảm_hoá\n   :mode imperative\n   :patient (t / tớ)\n   :agent (wz3 / c)\n   :polarity (wz5 / -)\n   :condition-of (m / muốn\n      :pivot (c / cậu)\n      :topic (c1 / có\n         :theme (n1 / người\n            :compound (b / bạn)\n            :quant (wz1 / 1))\n         :pivot (wz2 / c))\n      :polarity (wz4 / -)))\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-104006b2fe80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen_sent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'modified_graph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'gen_sent'"],"ename":"KeyError","evalue":"'gen_sent'","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"output_file = 'augmented_gen_sent_level.json'\nwith open(output_file, 'x', encoding='utf-8') as f:\n    json.dump(augmented, f, indent=4, ensure_ascii=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:17:18.997545Z","iopub.execute_input":"2025-04-17T09:17:18.997984Z","iopub.status.idle":"2025-04-17T09:17:19.014875Z","shell.execute_reply.started":"2025-04-17T09:17:18.997950Z","shell.execute_reply":"2025-04-17T09:17:19.013826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import fasttext.util\n# fasttext.util.download_model('vi', if_exists='ignore')\n# ft = fasttext.load_model('cc.vi.300.bin')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from gensim.models import KeyedVectors\n\n# # Load pretrained Vietnamese embeddings (e.g., fastText)\n# model = KeyedVectors.load_word2vec_format('cc.vi.300.vec')  # download from fastText\n\n# # Get similar words (approximate synonyms)\n# word = 'vui'\n# print(model.most_similar(word, topn=5))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}