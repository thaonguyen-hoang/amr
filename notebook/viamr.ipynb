{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text-to-AMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-22T06:51:54.295254Z",
     "iopub.status.busy": "2025-04-22T06:51:54.294838Z",
     "iopub.status.idle": "2025-04-22T06:52:09.038004Z",
     "shell.execute_reply": "2025-04-22T06:52:09.036870Z",
     "shell.execute_reply.started": "2025-04-22T06:51:54.295194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.7/159.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smatch\n",
      "  Downloading smatch-1.0.4.tar.gz (26 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: smatch\n",
      "  Building wheel for smatch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for smatch: filename=smatch-1.0.4-py3-none-any.whl size=24135 sha256=b17c0ac4255febd0342410c1bc4c7a69905fdeb8a92f46536ee238dd1aea7837\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/5e/2d/61b88bc74b337fbf3e998b9aa6b43bec72227e18a84a8335e8\n",
      "Successfully built smatch\n",
      "Installing collected packages: smatch\n",
      "Successfully installed smatch-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai\n",
    "!pip install smatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:52:13.281138Z",
     "iopub.status.busy": "2025-04-22T06:52:13.280820Z",
     "iopub.status.idle": "2025-04-22T06:52:14.840257Z",
     "shell.execute_reply": "2025-04-22T06:52:14.839503Z",
     "shell.execute_reply.started": "2025-04-22T06:52:13.281110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def few_shot_prompt(sent):\n",
    "#     prompt = f\"\"\"\n",
    "#     Translate the given sentence into AMR graph and give no more explanation. Below are some examples:\n",
    "#     Sentence: #::snt cứ mỗi năm hành tinh này lại quay nhanh hơn , thế mà điều lệnh không thay đổi !\n",
    "#     Graph:\n",
    "#     (c / contrast\n",
    "#     :ARG1(q / quay\n",
    "#         :frequency(n / năm)\n",
    "#         :theme(h / hành tinh\n",
    "#             :mod(n1 / này))\n",
    "#         :manner(n2 / nhanh\n",
    "#             :degree(h1 / hơn)))\n",
    "#     :ARG2(t1 / thay đổi\n",
    "#         :theme(đ / điều lệnh)\n",
    "#         :polarity(wz1 / -)))\n",
    "\n",
    "#     Sentence: #::snt - thế thì sao ? ông hoàng nhỏ hỏi .\n",
    "#     Graph:\n",
    "#     (h / hỏi\n",
    "#     :agent(ô / ông hoàng\n",
    "#         :mod(n / nhỏ))\n",
    "#     :topic(a / amr-unknown\n",
    "#         :domain(t / thế)\n",
    "#         :mode interrogative(wz1 / -)))\n",
    "\n",
    "#     Sentence: #::snt mỗi phút ta phải thắp đèn và phải tắt đèn một lần !\n",
    "#     Graph:\n",
    "#     (o / obligate-01\n",
    "#     :agent(t / ta)\n",
    "#     :frequency(r / rate-entity-91\n",
    "#         :ARG2(t1 / temporal-quantity\n",
    "#             :unit(p / phút)\n",
    "#             :quant(wz1 / 1)))\n",
    "#     :theme(a / and\n",
    "#         :op1(t2 / thắp\n",
    "#             :patient(đ / đèn)\n",
    "#             :agent(wz2 / t))\n",
    "#         :op2(t3 / tắt\n",
    "#             :agent(wz3 / t)\n",
    "#             :patient(wz4 / đ))))\n",
    "\n",
    "#     Sentence: {sent}\n",
    "#     Graph:\n",
    "#     \"\"\"\n",
    "#     return prompt\n",
    "\n",
    "# def get_answer(sent):\n",
    "#     response = client.models.generate_content(model='gemini-2.0-flash',\n",
    "#                                               contents=[few_shot_prompt(sent)])\n",
    "#     return response.text.strip()\n",
    "\n",
    "# def smatch_score(prediction, target):\n",
    "#     try:\n",
    "#         match_num, test_num, gold_num = smatch.get_amr_match(prediction, target)\n",
    "#     except:\n",
    "#         return -1, -1, -1\n",
    "#     else:\n",
    "#         precision, recall, f_score = smatch.compute_f(match_num, test_num, gold_num)\n",
    "#         return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# file = '/kaggle/input/amr-lda-01/viamr.txt'\n",
    "# pairs = []\n",
    "# with open(file, encoding='utf8') as f:\n",
    "#     data = f.read().split('\\n\\n')\n",
    "#     for sample in data:\n",
    "#         idx = sample.find('\\n')\n",
    "#         if idx != -1:\n",
    "#             pair = {'sent': sample[:idx],\n",
    "#                     'amr': sample[idx:].strip()}\n",
    "#             pairs.append(pair)\n",
    "#         else:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import smatch\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def evaluate():\n",
    "#     with open('output.txt', 'w', encoding='utf-8') as f:\n",
    "#         for pair in tqdm(pairs, total=len(pairs)):\n",
    "#             sent = pair['sent']\n",
    "#             graph = pair['amr']\n",
    "        \n",
    "#             model_answer = get_answer(sent)\n",
    "#             time.sleep(5)\n",
    "#             precision, recall, f_score = smatch_score(model_answer, graph)\n",
    "\n",
    "#             f.write(sent + '\\n')\n",
    "#             f.write(model_answer + '\\n\\n')\n",
    "            \n",
    "#             if precision == recall == f_score == -1:    \n",
    "#                 continue\n",
    "                \n",
    "#             pair['predict'] = model_answer\n",
    "#             pair['f-score'] = f_score\n",
    "#             print(f'gold AMR: \\n {graph}')\n",
    "#             print(f'parsed AMR: \\n {model_answer}')\n",
    "#             print(f'f-score: {f_score} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "    # doc_smatch = smatch.score_amr_pairs(file, '/kaggle/working/output.txt')\n",
    "# except:\n",
    "    # print('error processing')\n",
    "# else:\n",
    "    # print(doc_smatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMR-LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace space with underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:05:38.286813Z",
     "iopub.status.busy": "2025-04-04T07:05:38.286488Z",
     "iopub.status.idle": "2025-04-04T07:05:38.301014Z",
     "shell.execute_reply": "2025-04-04T07:05:38.299836Z",
     "shell.execute_reply.started": "2025-04-04T07:05:38.286785Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# base_dir = '/kaggle/input/amr-lda-01/viamr/final'\n",
    "# paths = [base_dir + '/' + fn for fn in os.listdir(base_dir)]\n",
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # check if two files are identical\n",
    "# f1 = open(paths[0], \"r\") \n",
    "# f2 = open(paths[2], \"r\") \n",
    "\n",
    "# f1_data = f1.readlines()\n",
    "# f2_data = f2.readlines()\n",
    "\n",
    "# for i in range(len(f1_data)):\n",
    "#     if f1_data[i] == f2_data[i]:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print(\"Line \", i, \":\")\n",
    "#         print(\"\\tFile 1:\", f1_data[i], end='')\n",
    "#         print(\"\\tFile 2:\", f2_data[i], end='')\n",
    "\n",
    "# # closing files\n",
    "# f1.close()\t\t\t\t\t\t\t\t\t \n",
    "# f2.close()\t\t\t\t\t\t\t\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:07:28.830389Z",
     "iopub.status.busy": "2025-04-04T07:07:28.830029Z",
     "iopub.status.idle": "2025-04-04T07:07:28.864104Z",
     "shell.execute_reply": "2025-04-04T07:07:28.862543Z",
     "shell.execute_reply.started": "2025-04-04T07:07:28.830362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# graphs = []\n",
    "# path = '/kaggle/input/amr-lda-01/user9_v3_1.txt'\n",
    "# fn = path.split('/')[-1][:-4]\n",
    "# with open(path, encoding='utf8') as f:\n",
    "#     data = f.read().split('\\n\\n')\n",
    "#     for sample in data[:-1]:\n",
    "#         idx = sample.find('\\n')\n",
    "#         texts.append(sample[:idx])\n",
    "#         graphs.append(sample[idx:].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:36:40.269010Z",
     "iopub.status.busy": "2025-03-30T16:36:40.268724Z",
     "iopub.status.idle": "2025-03-30T16:36:40.273610Z",
     "shell.execute_reply": "2025-03-30T16:36:40.272629Z",
     "shell.execute_reply.started": "2025-03-30T16:36:40.268990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def get_prompt(graph):\n",
    "#     prompt = f\"\"\"\n",
    "#     Replace blank space with underscore (_) in each instance of the AMR graph and keep everything else the same. Here is an example:\n",
    "#     Original:\n",
    "#     (b / bi kịch\n",
    "#         :domain(c / chỗ\n",
    "#             :mod(đ / đó)))\n",
    "\n",
    "#     Result:\n",
    "#     (b / bi_kịch\n",
    "#         :domain(c / chỗ\n",
    "#             :mod(đ / đó)))\n",
    "\n",
    "#     Original: {graph}\n",
    "#     Result:\n",
    "#     \"\"\"\n",
    "#     return prompt\n",
    "\n",
    "# def connect_words(graph):\n",
    "#     response = client.models.generate_content(model='gemini-2.0-flash',\n",
    "#                                               contents=[get_prompt(graph)])\n",
    "#     return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:36:51.254249Z",
     "iopub.status.busy": "2025-03-30T16:36:51.253905Z",
     "iopub.status.idle": "2025-03-30T16:36:51.258302Z",
     "shell.execute_reply": "2025-03-30T16:36:51.257617Z",
     "shell.execute_reply.started": "2025-03-30T16:36:51.254220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# def preprocess(graphs, output_file):\n",
    "#     with open(output_file, 'x', encoding='utf-8') as f:\n",
    "#         for graph in graphs:\n",
    "#             result = connect_words(graph)\n",
    "#             time.sleep(5)\n",
    "#             f.write(result + '\\n\\n')\n",
    "    \n",
    "#             # print(graph + '\\n')\n",
    "#             # print(result + '\\n\\n')\n",
    "#             # new_graphs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# new_graphs = preprocess(graphs, f'graphs_{fn}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:45:54.753426Z",
     "iopub.status.busy": "2025-04-22T06:45:54.753108Z",
     "iopub.status.idle": "2025-04-22T06:45:54.764973Z",
     "shell.execute_reply": "2025-04-22T06:45:54.764198Z",
     "shell.execute_reply.started": "2025-04-22T06:45:54.753401Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/viamr/reformat/reformat_user10_v3__user8_v2.txt',\n",
       " 'data/viamr/reformat/reformat_user10_v3__user9_v2.txt',\n",
       " 'data/viamr/reformat/reformat_user11_v3.txt',\n",
       " 'data/viamr/reformat/reformat_user8_v3.txt',\n",
       " 'data/viamr/reformat/reformat_user9_v3_1.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = 'data/viamr/reformat'\n",
    "paths = [base_dir + '/' + fn for fn in os.listdir(base_dir)]\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:46:01.562424Z",
     "iopub.status.busy": "2025-04-22T06:46:01.562111Z",
     "iopub.status.idle": "2025-04-22T06:46:01.586832Z",
     "shell.execute_reply": "2025-04-22T06:46:01.586048Z",
     "shell.execute_reply.started": "2025-04-22T06:46:01.562399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# total\n",
    "texts = []\n",
    "graphs = []\n",
    "for path in paths:\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        data = f.read().split('\\n\\n')\n",
    "        for sample in data[:]:\n",
    "            idx = sample.find('\\n')\n",
    "            texts.append(sample[:idx])\n",
    "            graphs.append(sample[idx:].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:46:04.058875Z",
     "iopub.status.busy": "2025-04-22T06:46:04.058617Z",
     "iopub.status.idle": "2025-04-22T06:46:04.063506Z",
     "shell.execute_reply": "2025-04-22T06:46:04.062848Z",
     "shell.execute_reply.started": "2025-04-22T06:46:04.058854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:46:06.902135Z",
     "iopub.status.busy": "2025-04-22T06:46:06.901845Z",
     "iopub.status.idle": "2025-04-22T06:46:06.907159Z",
     "shell.execute_reply": "2025-04-22T06:46:06.906458Z",
     "shell.execute_reply.started": "2025-04-22T06:46:06.902112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#::snt tôi có ba quả núi lửa .\n",
      "(c / có\n",
      "    :pivot(t / tôi)\n",
      "    :theme(n / núi_lửa\n",
      "        :quant 3\n",
      "            :classifier(q / quả)))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0, len(texts))\n",
    "print(texts[i])\n",
    "print(graphs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contraposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smatch\n",
    "def smatch_score(prediction, target):\n",
    "    try:\n",
    "        match_num, test_num, gold_num = smatch.get_amr_match(prediction, target)\n",
    "    except:\n",
    "        return -1\n",
    "    else:\n",
    "        precision, recall, f_score = smatch.compute_f(match_num, test_num, gold_num)\n",
    "        return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:46:19.602653Z",
     "iopub.status.busy": "2025-04-22T06:46:19.602423Z",
     "iopub.status.idle": "2025-04-22T06:46:19.618400Z",
     "shell.execute_reply": "2025-04-22T06:46:19.617791Z",
     "shell.execute_reply.started": "2025-04-22T06:46:19.602633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import penman\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:51.389941Z",
     "iopub.status.busy": "2025-04-22T07:06:51.389631Z",
     "iopub.status.idle": "2025-04-22T07:06:51.394064Z",
     "shell.execute_reply": "2025-04-22T07:06:51.393069Z",
     "shell.execute_reply.started": "2025-04-22T07:06:51.389911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def has_polarity_negative(g, z1):\n",
    "    for triple in g.triples:\n",
    "        if triple == (z1, ':polarity', '-'):\n",
    "            return triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:47:09.791606Z",
     "iopub.status.busy": "2025-04-22T06:47:09.791313Z",
     "iopub.status.idle": "2025-04-22T06:47:09.795676Z",
     "shell.execute_reply": "2025-04-22T06:47:09.794624Z",
     "shell.execute_reply.started": "2025-04-22T06:47:09.791585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_contra(g):\n",
    "    for inst in g.instances():\n",
    "        if (len(g.edges(source=inst.source, role=':condition')) == 1) and inst.target != 'and':\n",
    "            return inst.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contraposition(graph):\n",
    "    try:\n",
    "        g = penman.decode(graph)\n",
    "    except:\n",
    "        return []\n",
    "    else: \n",
    "        z0 = swappable_contra(g)\n",
    "        if z0 is None:\n",
    "            return []\n",
    "        z1 = g.edges(source=z0, role=':condition')[0].target\n",
    "        z1_neg = has_polarity_negative(g, z1)\n",
    "        z0_neg = has_polarity_negative(g, z0)\n",
    "\n",
    "        # add negative polarity to both clauses\n",
    "        if z1_neg is None and z0_neg is None:\n",
    "            g.triples.append((z1, ':polarity', '-'))\n",
    "            g.triples.append((z0, ':polarity', '-'))\n",
    "        elif z1_neg is not None and z0_neg is not None:\n",
    "            g.triples.remove(z1_neg)\n",
    "            g.triples.remove(z0_neg)\n",
    "        elif z1_neg is None and z0_neg is not None:\n",
    "            g.triples.remove(z0_neg)\n",
    "            g.triples.append((z1, ':polarity', '-'))\n",
    "        elif z1_neg is not None and z0_neg is None:\n",
    "            g.triples.remove(z1_neg)\n",
    "            g.triples.append((z0, ':polarity', '-'))\n",
    "\n",
    "        # modify root node\n",
    "        root = g.edges(target=z0)\n",
    "        if len(root) > 0:\n",
    "            g.triples.remove((root[0].source, root[0].role, z0))\n",
    "            g.triples.append((root[0].source, root[0].role, z1))\n",
    "\n",
    "        # change condition\n",
    "        g.triples.remove((z0, ':condition', z1))\n",
    "        g.triples.append((z1, ':condition', z0))\n",
    "\n",
    "        # # add modality\n",
    "        # new_node = random.choice([\"có_lẽ\", \"hẳn_là\", \"chắc_hẳn\", \"hẳn\"])\n",
    "        # new_node_id = new_node[0]\n",
    "        # i = 1\n",
    "        # while new_node_id in g.variables():\n",
    "        #     new_node_id += str(i)\n",
    "        #     i += 1\n",
    "        # g.triples.append((z1, ':modality', new_node_id))\n",
    "        # g.triples.append((new_node_id, ':instance', new_node))\n",
    "\n",
    "        try:\n",
    "            new_graph = penman.encode(g, indent=3)\n",
    "        except Exception as e:\n",
    "            print(graph)\n",
    "            print(g)\n",
    "            print(e)\n",
    "            return []\n",
    "        else:\n",
    "            return [{'aug_graph': new_graph, 'score': smatch_score(new_graph, graph)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swappable_conditions_contraposition_2(graph):\n",
    "    if \":condition\" in graph:\n",
    "        start = graph.index(\"(\")\n",
    "        end = graph.index(\":condition\")\n",
    "        # split_new_condition = \":condition \"+ graph[start:end] +\":polarity -)\"\n",
    "        split_new_condition = \":condition \" + graph[start:end]\n",
    "        # split_old_condition = graph[end+len(\":condition \"):len(graph)-2] + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        split_old_condition = graph[end + len(\":condition \"):len(graph) - 2]\n",
    "        pattern = r':degree \\([^)]+\\)'      \n",
    "\n",
    "        if \":polarity -\" not in split_new_condition and \":polarity -\" not in split_old_condition:\n",
    "            split_new_condition = split_new_condition + \":polarity -)\"\n",
    "            split_old_condition = split_old_condition + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        elif \":polarity -\" in split_new_condition and \":polarity -\" in split_old_condition:\n",
    "            split_new_condition = split_new_condition.replace(\":polarity -\",\"\") + \")\"\n",
    "            split_old_condition = split_old_condition.replace(\":polarity -\",\"\") + \"\\n\"\n",
    "            split_new_condition = re.sub(pattern, '', split_new_condition)\n",
    "            split_old_condition = re.sub(pattern, '', split_old_condition)          \n",
    "        elif \":polarity -\" not in split_new_condition and \":polarity -\" in split_old_condition:\n",
    "            split_new_condition = split_new_condition + \":polarity -)\"\n",
    "            split_old_condition = split_old_condition.replace(\":polarity -\",\"\") + \"\\n\"\n",
    "            split_old_condition = re.sub(pattern, '', split_old_condition)          \n",
    "        elif \":polarity -\" in split_new_condition and \":polarity -\" not in split_old_condition:\n",
    "            split_new_condition = split_new_condition.replace(\":polarity -\",\"\") + \")\"\n",
    "            split_new_condition = re.sub(pattern, '', split_new_condition)\n",
    "            split_old_condition = split_old_condition + \"\\n\" +\":polarity -\" + \"\\n\"          \n",
    "\n",
    "        new_contructed_graph = split_old_condition + split_new_condition + \")\"\n",
    "        dec_g = penman.decode(new_contructed_graph)\n",
    "        enc_g = penman.encode(dec_g, indent=3)\n",
    "        return new_contructed_graph\n",
    "        # return enc_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c / cố_gắng\n",
      "      :agent (t / tôi)\n",
      "      :topic (t1 / tả\n",
      "         :compound (l / lại)\n",
      "         :location (đ / đây\n",
      "            :prep (ở / ở))\n",
      "         :agent t\n",
      "         :goal (e / em)))\n",
      "   \n",
      "   :pivot t\n",
      "   :goal e\n",
      ":condition (q / quên\n",
      "   :polarity -))\n"
     ]
    }
   ],
   "source": [
    "test = '''\n",
    "(q / quên\n",
    "   :condition (c / cố_gắng\n",
    "      :agent (t / tôi)\n",
    "      :topic (t1 / tả\n",
    "         :compound (l / lại)\n",
    "         :location (đ / đây\n",
    "            :prep (ở / ở))\n",
    "         :agent t\n",
    "         :goal (e / em)))\n",
    "   :polarity -\n",
    "   :pivot t\n",
    "   :goal e)\n",
    "'''\n",
    "print(swappable_conditions_contraposition_2(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:03:02.668126Z",
     "iopub.status.busy": "2025-04-22T07:03:02.667797Z",
     "iopub.status.idle": "2025-04-22T07:03:02.676408Z",
     "shell.execute_reply": "2025-04-22T07:03:02.675515Z",
     "shell.execute_reply.started": "2025-04-22T07:03:02.668097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def contraposition_all(graphs, texts):\n",
    "    return_list = []\n",
    "    label_list = []\n",
    "    sentence_list = []\n",
    "    graph_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        try:\n",
    "            g = penman.decode(graph)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            z0 = swappable_contra(g)\n",
    "            if z0 is None:\n",
    "                continue\n",
    "            negative_sample_g = copy.deepcopy(g)\n",
    "            z1 = g.edges(source=z0, role=':condition')[0].target\n",
    "            z1_neg = has_polarity_negative(g, z1)\n",
    "            z0_neg = has_polarity_negative(g, z0)\n",
    "            \n",
    "            # add negative polarity to both clauses\n",
    "            if z1_neg is None and z0_neg is None:\n",
    "                # wzs = len([wz for wz in g.variables() if 'wz' in wz])\n",
    "                # g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n",
    "                g.triples.append((z1, ':polarity', '-'))\n",
    "                # g.triples.append((f'wz{wzs+2}', ':instance', '-'))\n",
    "                g.triples.append((z0, ':polarity', '-'))\n",
    "                # negative sample\n",
    "                # negative_sample_g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n",
    "                # negative_sample_g.triples.append((z0, ':polarity', f'wz{wzs+1}'))\n",
    "            elif z1_neg is not None and z0_neg is not None:\n",
    "                # g.triples.remove((z1_neg, ':instance', '-'))\n",
    "                g.triples.remove(z1_neg)\n",
    "                # g.triples.remove((z0_neg, ':instance', '-'))\n",
    "                g.triples.remove(z0_neg)\n",
    "                # negative sample\n",
    "                # negative_sample_g.triples.remove((z0_neg.target, ':instance', '-'))\n",
    "                # negative_sample_g.triples.remove(z0_neg)\n",
    "            elif z1_neg is None and z0_neg is not None:\n",
    "                # g.triples.remove((z0_neg, ':instance', '-'))\n",
    "                g.triples.remove(z0_neg)\n",
    "                # wzs = len([wz for wz in g.variables() if 'wz' in wz])\n",
    "                # g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n",
    "                g.triples.append((z1, ':polarity', '-'))\n",
    "                # negative sample\n",
    "                # negative_sample_g.triples.remove((z0_neg.target, ':instance', '-'))\n",
    "                # negative_sample_g.triples.remove(z0_neg)\n",
    "            elif z1_neg is not None and z0_neg is None:\n",
    "                # g.triples.remove((z1_neg, ':instance', '-'))\n",
    "                g.triples.remove(z1_neg)\n",
    "                # wzs = len([wz for wz in g.variables() if 'wz' in wz])\n",
    "                # g.triples.append((f'wz{wzs+1}', ':instance', '-'))\n",
    "                g.triples.append((z0, ':polarity', '-'))\n",
    "                # negative sample\n",
    "                # negative_sample_g.triples.remove((z1_neg.target, ':instance', '-'))\n",
    "                # negative_sample_g.triples.remove(z1_neg)\n",
    "\n",
    "            # switch condition\n",
    "            g.triples.remove((z0, ':condition', z1))\n",
    "            g.triples.append((z1, ':condition', z0))\n",
    "            # g.metadata = {}\n",
    "            # g.epidata = {}\n",
    "            # print(g)\n",
    "\n",
    "            # new_triples = []\n",
    "            # for triple in g.triples:\n",
    "            #     subj, role, obj = triple\n",
    "            \n",
    "            #     # Replace subject or object if it matches old ID\n",
    "            #     subj = z0 if subj == z1 else subj\n",
    "            #     obj = z1 if obj == old_id else obj\n",
    "            \n",
    "            #     # Replace the instance triple with the new concept\n",
    "            #     if triple == (old_id, 'instance', 'boy'):\n",
    "            #         new_triples.append((new_id, 'instance', new_concept))\n",
    "            #     else:\n",
    "            #         new_triples.append((subj, role, obj))\n",
    "            \n",
    "            # # Update the graph with the new triples\n",
    "            # graph.triples = new_triples\n",
    "            \n",
    "            try:\n",
    "                new_graph = penman.encode(g, indent=3)\n",
    "            except Exception as e:\n",
    "                print(texts[index])\n",
    "                print(graph)\n",
    "                print(g)\n",
    "                print(e)\n",
    "                continue\n",
    "            else:\n",
    "                return_list.append(new_graph)\n",
    "                label_list.append(1)\n",
    "                sentence_list.append(texts[index])\n",
    "                graph_list.append(graph)\n",
    "    return return_list, label_list, sentence_list, graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:47:15.746427Z",
     "iopub.status.busy": "2025-04-22T06:47:15.746136Z",
     "iopub.status.idle": "2025-04-22T06:47:15.750949Z",
     "shell.execute_reply": "2025-04-22T06:47:15.750014Z",
     "shell.execute_reply.started": "2025-04-22T06:47:15.746399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_impli(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'or'   ## this elif is working for implication law\n",
    "         and len(g.edges(source=inst.source, role=':op1')) == 1\n",
    "         and len(g.edges(source=inst.source, role=':op2')) == 1\n",
    "         and len(g.edges(target=inst.source)) == 0):\n",
    "            yield inst.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:03:23.711302Z",
     "iopub.status.busy": "2025-04-22T07:03:23.710939Z",
     "iopub.status.idle": "2025-04-22T07:03:23.723240Z",
     "shell.execute_reply": "2025-04-22T07:03:23.722459Z",
     "shell.execute_reply.started": "2025-04-22T07:03:23.711267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def implication_negative(g, z1):\n",
    "    z1_neg = has_polarity_negative(g, z1)\n",
    "    if z1_neg is None:\n",
    "        g.triples.append((z1, ':polarity', '-'))\n",
    "    else:\n",
    "        g.triples.remove(z1_neg)\n",
    "    return g\n",
    "\n",
    "def implication(graph):\n",
    "    '''A -> B = not(A) or B'''\n",
    "    try:\n",
    "        g = penman.decode(graph)\n",
    "    except:\n",
    "        return []\n",
    "    else:\n",
    "        augs = []\n",
    "        z0 = swappable_contra(g)\n",
    "        if z0 is not None:\n",
    "            root = g.edges(target=z0)\n",
    "            if len(root) == 0:\n",
    "                z1 = g.edges(source=z0, role=':condition')[0].target\n",
    "                # add negative polarity\n",
    "                g = implication_negative(g, z1)\n",
    "                # 'condition' -> 'or'\n",
    "                os = len([wz for wz in g.variables() if wz.startswith('o')])\n",
    "                source = 'o' if os == 0 else f'o{os}'\n",
    "                g.triples.remove((z0, ':condition', z1))\n",
    "                g.triples.append((source, ':instance', 'or'))\n",
    "                g.triples.append((source, ':op1', z1))\n",
    "                g.triples.append((source, ':op2', z0))\n",
    "\n",
    "                try:\n",
    "                    new_graph = penman.encode(g, indent=3, top=source)\n",
    "                except Exception as e:\n",
    "                    # print(graph)\n",
    "                    # print(g)\n",
    "                    # print(e)\n",
    "                    return []\n",
    "                else:\n",
    "                    augs += [{'aug_graph': new_graph, 'score': smatch_score(new_graph, graph)}]\n",
    "        else:\n",
    "            for z in swappable_impli(g):\n",
    "                root = g.edges(target=z)\n",
    "                if len(root) == 0:\n",
    "                    g_temp = copy.deepcopy(g)\n",
    "                    ## A or B\n",
    "                    z1 = g.edges(source=z, role=':op1')[0].target\n",
    "                    z5 = g.edges(source=z, role=':op2')[0].target\n",
    "                    \n",
    "                    # add negative polarity\n",
    "                    g = implication_negative(g, z1)\n",
    "                    \n",
    "                    # 'or' -> 'condition'\n",
    "                    g.triples.remove((z, ':instance', 'or'))\n",
    "                    g.triples.remove((z, ':op1', z1))\n",
    "                    g.triples.remove((z, ':op2', z5))\n",
    "                    g.triples.append((z5, ':condition', z1))\n",
    "                    \n",
    "                    g.metadata = {}\n",
    "                    g.epidata = {}\n",
    "                    try:\n",
    "                        new_graph = penman.encode(g, indent=3, top=z5)\n",
    "                    except:\n",
    "                        return augs\n",
    "                    else:\n",
    "                        augs.append({'aug_graph': new_graph, 'score': smatch_score(new_graph, graph)})\n",
    "                    \n",
    "                    ## B or A\n",
    "                    # add negative polarity\n",
    "                    g_temp = implication_negative(g_temp, z5)\n",
    "\n",
    "                    # 'or' -> 'condition'\n",
    "                    g_temp.triples.remove((z, ':instance', 'or'))\n",
    "                    g_temp.triples.remove((z, ':op1', z1))\n",
    "                    g_temp.triples.remove((z, ':op2', z5))\n",
    "                    g_temp.triples.append((z1, ':condition', z5))\n",
    "                    \n",
    "                    g_temp.metadata = {}\n",
    "                    g_temp.epidata = {}\n",
    "                    try:\n",
    "                        new_graph_temp = penman.encode(g_temp, indent=3, top=z1)\n",
    "                    except:\n",
    "                        return augs\n",
    "                    else:\n",
    "                        augs.append({'aug_graph': new_graph_temp, 'score': smatch_score(new_graph, graph)})\n",
    "        return augs\n",
    "            \n",
    "# def implication_all(graphs, texts):\n",
    "    '''A -> B = not(A) or B'''\n",
    "    return_list = []\n",
    "    label_list = []\n",
    "    sentence_list = []\n",
    "    graph_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        try:\n",
    "            g = penman.decode(graph)\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            z0 = swappable_contra(g)\n",
    "            # negative_sample_g = copy.deepcopy(g)\n",
    "            if z0 is not None:\n",
    "                root = g.edges(target=z0)\n",
    "                if len(root) == 0:\n",
    "                    z1 = g.edges(source=z0, role=':condition')[0].target\n",
    "                    # add negative polarity\n",
    "                    g = implication_negative(g, z1)\n",
    "                \n",
    "                    # 'condition' -> 'or'\n",
    "                    os = len([wz for wz in g.variables() if wz.startswith('o')])\n",
    "                    source = 'o' if os == 0 else f'o{os}'\n",
    "                    g.triples.remove((z0, ':condition', z1))\n",
    "                    g.triples.append((source, ':instance', 'or'))\n",
    "                    g.triples.append((source, ':op1', z1))\n",
    "                    g.triples.append((source, ':op2', z0))\n",
    "    \n",
    "                    \n",
    "                    new_graph = penman.encode(g, indent=3, top=source)\n",
    "                    return_list.append(new_graph)\n",
    "                    label_list.append(1)\n",
    "                    sentence_list.append(texts[index])\n",
    "                    graph_list.append(graph)\n",
    "            else:\n",
    "                for z in swappable_impli(g):\n",
    "                    root = g.edges(target=z)\n",
    "                    if len(root) == 0:\n",
    "                        g_temp = copy.deepcopy(g)\n",
    "                        ## A or B\n",
    "                        z1 = g.edges(source=z, role=':op1')[0].target\n",
    "                        z5 = g.edges(source=z, role=':op2')[0].target\n",
    "                        \n",
    "                        # add negative polarity\n",
    "                        g = implication_negative(g, z1)\n",
    "                        \n",
    "                        # 'or' -> 'condition'\n",
    "                        # z_root = g.edges(target=z)[0]\n",
    "                        g.triples.remove((z, ':instance', 'or'))\n",
    "                        g.triples.remove((z, ':op1', z1))\n",
    "                        g.triples.remove((z, ':op2', z5))\n",
    "                        g.triples.append((z5, ':condition', z1))\n",
    "                        # if z_root is not None:\n",
    "                        #     print(graph)\n",
    "                        #     z_source = z_root.source\n",
    "                        #     z_role = z_root.role\n",
    "                        #     g.triples.remove(z_root)\n",
    "                        #     g.triples.append((z_source, z_role, z5))\n",
    "                        g.metadata = {}\n",
    "                        g.epidata = {}\n",
    "                        try:\n",
    "                            new_graph = penman.encode(g, top=z5, indent=3)\n",
    "                        except:\n",
    "                            # print(g)\n",
    "                            # print(graph)\n",
    "                            continue\n",
    "                        else:\n",
    "                            return_list.append(new_graph)\n",
    "                            label_list.append(1)\n",
    "                            sentence_list.append(texts[index])\n",
    "                            graph_list.append(graph)\n",
    "                        \n",
    "                        ## B or A\n",
    "                        # add negative polarity\n",
    "                        g_temp = implication_negative(g_temp, z5)\n",
    "    \n",
    "                        # 'or' -> 'condition'\n",
    "                        # z_root = g.edges(target=z)[0]\n",
    "                        g_temp.triples.remove((z, ':instance', 'or'))\n",
    "                        g_temp.triples.remove((z, ':op1', z1))\n",
    "                        g_temp.triples.remove((z, ':op2', z5))\n",
    "                        g_temp.triples.append((z1, ':condition', z5))\n",
    "                        # if z_root is not None:\n",
    "                        #     print(graph)\n",
    "                        #     z_source = z_root.source\n",
    "                        #     z_role = z_root.role\n",
    "                        #     g.triples.remove(z_root)\n",
    "                        #     g.triples.append((z_source, z_role, z1))\n",
    "                        g_temp.metadata = {}\n",
    "                        g_temp.epidata = {}\n",
    "                        try:\n",
    "                            new_graph_temp = penman.encode(g_temp, indent=3, top=z1)\n",
    "                        except:\n",
    "                            # print(g_temp)\n",
    "                            # print(graph)\n",
    "                            continue\n",
    "                        else:\n",
    "                            return_list.append(new_graph_temp)\n",
    "                            label_list.append(1)\n",
    "                            sentence_list.append(texts[index])\n",
    "                            graph_list.append(graph)\n",
    "    return return_list, label_list, sentence_list, graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:01:41.422188Z",
     "iopub.status.busy": "2025-04-22T07:01:41.421844Z",
     "iopub.status.idle": "2025-04-22T07:01:41.431622Z",
     "shell.execute_reply": "2025-04-22T07:01:41.430807Z",
     "shell.execute_reply.started": "2025-04-22T07:01:41.422156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_commu(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'and'   # find sentence with 'and'\n",
    "         and len(g.edges(source=inst.source, role=':op1')) == 1 # make sure it has at least 2 clauses\n",
    "         and len(g.edges(source=inst.source, role=':op2')) == 1\n",
    "         and len(g.edges(target=inst.source)) == 0):\n",
    "            yield inst.source\n",
    "\n",
    "def swappable_commu_2(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'contrast-01'   # find sentence with 'and'\n",
    "         and len(g.edges(source=inst.source, role=':ARG1')) == 1 # make sure it has at least 2 clauses\n",
    "         and len(g.edges(source=inst.source, role=':ARG2')) == 1\n",
    "         and len(g.edges(target=inst.source)) == 0):\n",
    "            yield inst.source\n",
    "\n",
    "def switch_node(g, source, relations):\n",
    "    z1 = g.edges(source=source, role=relations[0])[0].target\n",
    "    z5 = g.edges(source=source, role=relations[1])[0].target\n",
    "    g.triples.remove((source, relations[0], z1))  # remove the triples\n",
    "    g.triples.remove((source, relations[1], z5))\n",
    "    g.triples.append((source, relations[0], z5))  # add the replacements\n",
    "    g.triples.append((source, relations[1], z1))\n",
    "    return g\n",
    "\n",
    "def get_leaves(g):\n",
    "    var = g.variables()\n",
    "    leaves = []\n",
    "    for v in var:\n",
    "        # get leaf node, remove node with re-entrancy\n",
    "        if len(g.edges(source=v)) == 0 and len(g.edges(target=v)) == 1:\n",
    "            leaves.append([t for t in g.triples if t[0] == v or t[2] == v])\n",
    "    return leaves\n",
    "\n",
    "def get_same_level_pairs(g):\n",
    "    leaves = get_leaves(g)\n",
    "    pairs = {}\n",
    "    for i in range(len(leaves) - 1):\n",
    "        for j in range(i, len(leaves)):\n",
    "            if i != j and leaves[i][0][0] == leaves[j][0][0]:\n",
    "                pairs[leaves[i][0][0]] = [leaves[i][0][1], leaves[j][0][1]]\n",
    "    return pairs\n",
    "\n",
    "# def commutative_negative(g, source, relations):\n",
    "#     # negative_sample_g = copy.deepcopy(g)\n",
    "#     z1 = g.edges(source=source, role=relations[0])[0].target\n",
    "#     z5 = g.edges(source=source, role=relations[1])[0].target\n",
    "#     z1_neg = has_polarity_negative(g, z1)\n",
    "#     z5_neg = has_polarity_negative(g, z5)\n",
    "    \n",
    "#     if z1_neg is None and z5_neg is None:\n",
    "#         g.triples.append((z5, ':polarity', '-'))\n",
    "#     elif z5_neg is not None:\n",
    "#         g.triples.remove(z5_neg)\n",
    "#     elif z1_neg is not None:\n",
    "#         g.triples.remove(z1_neg)\n",
    "#     return g\n",
    "\n",
    "def commutative(graph):\n",
    "    try:\n",
    "        g = penman.decode(graph)\n",
    "    except:\n",
    "        return\n",
    "    else:\n",
    "        sources = list(swappable_commu(g)) + list(swappable_impli(g)) + list(swappable_commu_2(g))\n",
    "        if len(sources) == 0:\n",
    "            return\n",
    "        for z0 in sources:\n",
    "            if z0.startswith('c'):\n",
    "                relations = [':ARG1', ':ARG2']\n",
    "            else:\n",
    "                relations = [':op1', ':op2']\n",
    "            g = switch_node(g, z0, relations)\n",
    "        new_graph = penman.encode(g, indent=3)\n",
    "        return {'aug_graph': new_graph, 'score': smatch_score(new_graph, graph)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(graph):\n",
    "    test_g = penman.decode(graphs[100])\n",
    "    random.shuffle(test_g.triples)\n",
    "    test_enc = penman.encode(test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': [':agent', ':modality']}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_same_level_pairs(penman.decode(graphs[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring epigraph data for duplicate triple: ('l', ':domain', 'n')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':agent', 'ô')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':pivot', 'g')\n",
      "cannot deinvert attribute: ('c4', ':part-of', 't')\n"
     ]
    }
   ],
   "source": [
    "contra_list = []\n",
    "for g in graphs:\n",
    "    aug_contra = contraposition(g)\n",
    "    if len(aug_contra) > 0:\n",
    "        contra_list.append(aug_contra[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring epigraph data for duplicate triple: ('l', ':domain', 'n')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':agent', 'ô')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':pivot', 'g')\n",
      "cannot deinvert attribute: ('c4', ':part-of', 't')\n"
     ]
    }
   ],
   "source": [
    "impli_list = []\n",
    "for g in graphs:\n",
    "    aug_impli = implication(g)\n",
    "    if len(aug_impli) > 0:\n",
    "        impli_list += aug_impli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring epigraph data for duplicate triple: ('l', ':domain', 'n')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':agent', 'ô')\n",
      "ignoring epigraph data for duplicate triple: ('c', ':pivot', 'g')\n",
      "cannot deinvert attribute: ('c4', ':part-of', 't')\n"
     ]
    }
   ],
   "source": [
    "commu_list = []\n",
    "for g in graphs:\n",
    "    aug_commu = commutative(g)\n",
    "    if aug_commu is not None:\n",
    "        commu_list.append(aug_commu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:06:56.937136Z",
     "iopub.status.busy": "2025-04-22T07:06:56.936838Z",
     "iopub.status.idle": "2025-04-22T07:06:58.078588Z",
     "shell.execute_reply": "2025-04-22T07:06:58.077939Z",
     "shell.execute_reply.started": "2025-04-22T07:06:56.937110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "contraposition_list = []\n",
    "\n",
    "contraposition_list= contraposition(graphs, texts)\n",
    "commutative_list = commutative(graphs, texts)\n",
    "implication_list = implication(graphs, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:07:01.655497Z",
     "iopub.status.busy": "2025-04-22T07:07:01.655190Z",
     "iopub.status.idle": "2025-04-22T07:07:01.660825Z",
     "shell.execute_reply": "2025-04-22T07:07:01.659937Z",
     "shell.execute_reply.started": "2025-04-22T07:07:01.655465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  1522\n",
      "contraposition:  51\n",
      "commutative:  205\n",
      "implication:  31\n"
     ]
    }
   ],
   "source": [
    "print('total: ', len(graphs))\n",
    "print('contraposition: ', len(contraposition_list))\n",
    "print('commutative: ', len(commutative_list))\n",
    "print('implication: ', len(implication_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:07:04.081971Z",
     "iopub.status.busy": "2025-04-22T07:07:04.081645Z",
     "iopub.status.idle": "2025-04-22T07:07:04.087429Z",
     "shell.execute_reply": "2025-04-22T07:07:04.086477Z",
     "shell.execute_reply.started": "2025-04-22T07:07:04.081940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "augmented = []\n",
    "for i in range(len(contraposition_list)):\n",
    "    augmented.append({'source': contraposition_sentence_list[i],\n",
    "                      'original_graph': contraposition_graph_list[i],\n",
    "                      'modified_graph': contraposition_list[i], \n",
    "                      'tag': 'contraposition'})\n",
    "\n",
    "for i in range(len(commutative_list)):\n",
    "    augmented.append({'source': commutative_sentence_list[i],\n",
    "                      'original_graph': commutative_graph_list[i],\n",
    "                      'modified_graph': commutative_list[i], \n",
    "                      'tag': 'commutative'})\n",
    "\n",
    "for i in range(len(implication_list)):\n",
    "    augmented.append({'source': implication_sentence_list[i],\n",
    "                      'original_graph': implication_graph_list[i],\n",
    "                      'modified_graph': implication_list[i], \n",
    "                      'tag': 'implication'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T07:07:06.581621Z",
     "iopub.status.busy": "2025-04-22T07:07:06.581348Z",
     "iopub.status.idle": "2025-04-22T07:07:06.594177Z",
     "shell.execute_reply": "2025-04-22T07:07:06.593419Z",
     "shell.execute_reply.started": "2025-04-22T07:07:06.581598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_file = 'augmented_sent_level.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(augmented, f, indent=3, ensure_ascii=False)\n",
    "    # for item in augmented:\n",
    "    #     f.write('#::tag ' + item['tag'] + '\\n')\n",
    "    #     f.write(item['source'] + '\\n')\n",
    "    #     f.write(item['original_graph'] + '\\n')\n",
    "    #     f.write(item['modified_graph'] + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T04:01:11.773123Z",
     "iopub.status.busy": "2025-04-04T04:01:11.772338Z",
     "iopub.status.idle": "2025-04-04T04:01:13.385191Z",
     "shell.execute_reply": "2025-04-04T04:01:13.384352Z",
     "shell.execute_reply.started": "2025-04-04T04:01:11.773057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import wordnet\n",
    "\n",
    "# def double_negation(graphs, sentence_list):\n",
    "#     return_list = []\n",
    "#     negative_list = []\n",
    "#     label_list = []\n",
    "#     sentence_and_tag_list = []\n",
    "#     return_sents = []\n",
    "#     returned_sentence_and_tag_list = []\n",
    "#     if graphs is None:\n",
    "#         return\n",
    "#     for index, graph in enumerate(graphs):\n",
    "#         if graph is None:\n",
    "#             continue\n",
    "#         g = penman.decode(graph)\n",
    "#         updated_g = copy.deepcopy(g)\n",
    "#         negative_g = copy.deepcopy(g)\n",
    "#         if \":polarity -\" not in graph:  ## We only consider the case that the sentence does not have negation.\n",
    "#             z0 = updated_g.instances()[0].source\n",
    "#             updated_g.triples.append((z0, ':polarity', '-'))\n",
    "#             temp_graph = penman.encode(updated_g)\n",
    "#             start = temp_graph.index(\"\\n\")\n",
    "#             return_list.append(temp_graph[start+1:len(temp_graph)])\n",
    "#             sentence_and_tag_list.append(sentence_list[index])\n",
    "#             negative_list.append(penman.encode(negative_g))\n",
    "\n",
    "#     if len(return_list) > 0:\n",
    "#         gtos = amrlib.load_gtos_model(\"/kaggle/input/amr-lda-01/models/generate_t5wtense\")\n",
    "#         sents, _ = gtos.generate(return_list)\n",
    "#         punctuation_string = string.punctuation\n",
    "\n",
    "#         for idx, sent in enumerate(sents):\n",
    "#             temp_sent = copy.deepcopy(sent)\n",
    "#             for i in punctuation_string:\n",
    "#                 temp_sent = temp_sent.replace(i, '')\n",
    "#             splited_sent = temp_sent.split()\n",
    "#             for stem in splited_sent:\n",
    "#                 if len(wordnet.synsets(stem)) > 0:\n",
    "#                     syn = wordnet.synsets(stem)[0]\n",
    "#                     good = wordnet.synset(syn.name())\n",
    "#                     antonym = good.lemmas()[0].antonyms()\n",
    "#                     if len(antonym) > 0:\n",
    "#                         if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n",
    "#                             sent = sent.replace(stem,antonym[0].name())\n",
    "#                             returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n",
    "#                             return_sents.append(sent)\n",
    "#                             label_list.append(1)\n",
    "#                             break\n",
    "\n",
    "#         neg_sents, _ = gtos.generate(negative_list)\n",
    "\n",
    "#         for idx, sent in enumerate(neg_sents):\n",
    "#             temp_sent = copy.deepcopy(sent)\n",
    "#             for i in punctuation_string:\n",
    "#                 temp_sent = temp_sent.replace(i, '')\n",
    "#             splited_sent = temp_sent.split()\n",
    "#             for stem in splited_sent:\n",
    "#                 if len(wordnet.synsets(stem)) > 0:\n",
    "#                     syn = wordnet.synsets(stem)[0]\n",
    "#                     good = wordnet.synset(syn.name())\n",
    "#                     antonym = good.lemmas()[0].antonyms()\n",
    "#                     if len(antonym) > 0:\n",
    "#                         if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n",
    "#                             sent = sent.replace(stem, antonym[0].name())\n",
    "#                             returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n",
    "#                             return_sents.append(sent)\n",
    "#                             label_list.append(0)\n",
    "#                             break\n",
    "\n",
    "#     return return_sents, label_list, returned_sentence_and_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T04:06:48.608299Z",
     "iopub.status.busy": "2025-04-04T04:06:48.607919Z",
     "iopub.status.idle": "2025-04-04T04:06:48.616460Z",
     "shell.execute_reply": "2025-04-04T04:06:48.615575Z",
     "shell.execute_reply.started": "2025-04-04T04:06:48.608272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# syn = wordnet.synsets('cancel')[0]\n",
    "# syn.lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T11:41:22.293819Z",
     "iopub.status.busy": "2025-04-15T11:41:22.293356Z",
     "iopub.status.idle": "2025-04-15T11:41:22.304796Z",
     "shell.execute_reply": "2025-04-15T11:41:22.303812Z",
     "shell.execute_reply.started": "2025-04-15T11:41:22.293781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import penman\n",
    "\n",
    "# # Original AMR\n",
    "# amr_str = \"\"\"\n",
    "# (w / want-01\n",
    "#    :arg0 (b / boy)\n",
    "#    :arg1 (g / go-01\n",
    "#              :arg0 b))\n",
    "# \"\"\"\n",
    "\n",
    "# # Parse the AMR\n",
    "# graph = penman.decode(amr_str)\n",
    "\n",
    "# # Old and new node info\n",
    "# old_id = 'b'\n",
    "# new_id = 'c'\n",
    "# new_concept = 'child'\n",
    "\n",
    "# # Step 1: Update all triples where the old ID appears\n",
    "# new_triples = []\n",
    "# for triple in graph.triples:\n",
    "#     subj, role, obj = triple\n",
    "\n",
    "#     # Replace subject or object if it matches old ID\n",
    "#     subj = new_id if subj == old_id else subj\n",
    "#     obj = new_id if obj == old_id else obj\n",
    "\n",
    "#     # Replace the instance triple with the new concept\n",
    "#     if triple == (old_id, 'instance', 'boy'):\n",
    "#         new_triples.append((new_id, 'instance', new_concept))\n",
    "#     else:\n",
    "#         new_triples.append((subj, role, obj))\n",
    "\n",
    "# # Update the graph with the new triples\n",
    "# graph.triples = new_triples\n",
    "\n",
    "# # Convert back to AMR string\n",
    "# new_amr_str = penman.encode(graph, indent=6)\n",
    "# print(new_amr_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMR-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T06:50:32.389889Z",
     "iopub.status.busy": "2025-04-22T06:50:32.389568Z",
     "iopub.status.idle": "2025-04-22T06:50:32.395131Z",
     "shell.execute_reply": "2025-04-22T06:50:32.394111Z",
     "shell.execute_reply.started": "2025-04-22T06:50:32.389864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_prompt(graph):\n",
    "    prompt = f\"\"\"\n",
    "    ## Instruction \n",
    "    You are an Vietnamese expert linguist. Your task is to generate a sentence according to the given abstract meaning representation (AMR), \n",
    "    which is a semantic parsing of a sentence with roles and concepts.\n",
    "\n",
    "    ## Constraints \n",
    "    Follow some additional rules and notes when generating sentences: \n",
    "    - “:classifier” is used for noun classifier, which standing before a noun. \n",
    "    - “:compound” is used for compound word. \n",
    "    - “:mode” indicates type of sentence. For example: “imperative” for commands or instructions or suggestions, \n",
    "        “interrogative” or “amr-unknown ” for questions, “expressive” for sentence with exclamational words that express emotions. \n",
    "    - “:polarity -“ is used for negatives. \n",
    "    - “a / and”, “o / or”, “m / multi-sentence” indicate sentences with multiple clauses or multiple sentences that are connected. \n",
    "    - nodes with the same id refer to the same entity. For example: “(a / and :op1(n / nghĩ :pivot(wz / e)) :op2(n1 / nói :agent(em / e)))” has the first “e” also referring to “em”.\n",
    "    - the sentence should be natural and understandable. make sure to include all components of the AMR in the sentence \n",
    "    and stick to the original words in AMR as close as possible.\n",
    "\n",
    "    ## Input\n",
    "    Graph: {graph}\n",
    "    Sentence:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def generate(graph):\n",
    "    response = client.models.generate_content(model='gemini-2.0-flash',\n",
    "                                              contents=[get_prompt(graph)])\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "commu = []\n",
    "for item in tqdm(augmented, total=len(augmented)):\n",
    "    if item['tag'] == 'commutative':\n",
    "        result = generate(item['modified_graph'])\n",
    "        item['gen_sent'] = result\n",
    "        commu.append(item)\n",
    "        time.sleep(5)\n",
    "        \n",
    "# for item in tqdm(augmented, total=len(augmented)):\n",
    "#     result = generate(item['modified_graph'])\n",
    "#     item['gen_sent'] = result\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for item in commu:\n",
    "    print(item['gen_sent'], end='\\n') \n",
    "    print(item['modified_graph'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T09:17:18.997984Z",
     "iopub.status.busy": "2025-04-17T09:17:18.997545Z",
     "iopub.status.idle": "2025-04-17T09:17:19.014875Z",
     "shell.execute_reply": "2025-04-17T09:17:19.013826Z",
     "shell.execute_reply.started": "2025-04-17T09:17:18.997950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_file = 'augmented_gen_sent_level.json'\n",
    "with open(output_file, 'x', encoding='utf-8') as f:\n",
    "    json.dump(augmented, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import fasttext.util\n",
    "# fasttext.util.download_model('vi', if_exists='ignore')\n",
    "# ft = fasttext.load_model('cc.vi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Load pretrained Vietnamese embeddings (e.g., fastText)\n",
    "# model = KeyedVectors.load_word2vec_format('cc.vi.300.vec')  # download from fastText\n",
    "\n",
    "# # Get similar words (approximate synonyms)\n",
    "# word = 'vui'\n",
    "# print(model.most_similar(word, topn=5))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6707467,
     "sourceId": 11771114,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
