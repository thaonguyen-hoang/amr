{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install amrlib\n",
    "%pip install sacrebleu\n",
    "%pip install unidecode\n",
    "%pip install word2number\n",
    "%unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T05:50:25.244338Z",
     "iopub.status.busy": "2025-02-21T05:50:25.244027Z",
     "iopub.status.idle": "2025-02-21T05:50:30.732702Z",
     "shell.execute_reply": "2025-02-21T05:50:30.731679Z",
     "shell.execute_reply.started": "2025-02-21T05:50:25.244314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import amrlib\n",
    "import penman\n",
    "import json\n",
    "import pandas as pd\n",
    "import sacrebleu\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test AMR-text conversion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:33:15.061960Z",
     "iopub.status.busy": "2025-02-20T17:33:15.061665Z",
     "iopub.status.idle": "2025-02-20T17:33:16.778528Z",
     "shell.execute_reply": "2025-02-20T17:33:16.777814Z",
     "shell.execute_reply.started": "2025-02-20T17:33:15.061939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt He wanted the girl to believe him.\n",
      "(w / want-01\n",
      "      :ARG0 (h / he)\n",
      "      :ARG1 (b / believe-01\n",
      "            :ARG0 (g / girl)\n",
      "            :ARG1 h))\n",
      "# ::snt If i were you, i would give up\n",
      "(h / have-condition-91\n",
      "      :ARG1 (g / give-up-07\n",
      "            :ARG0 (ii / i))\n",
      "      :ARG2 (y / you\n",
      "            :domain ii))\n"
     ]
    }
   ],
   "source": [
    "stog = amrlib.load_stog_model('/kaggle/input/amr-lda-01/models/parse_xfm_bart_large')\n",
    "graphs = stog.parse_sents(['He wanted the girl to believe him.', 'If i were you, i would give up'])\n",
    "for graph in graphs:\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:33:26.564249Z",
     "iopub.status.busy": "2025-02-20T17:33:26.563934Z",
     "iopub.status.idle": "2025-02-20T17:33:27.791464Z",
     "shell.execute_reply": "2025-02-20T17:33:27.790757Z",
     "shell.execute_reply.started": "2025-02-20T17:33:26.564225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He wanted the girl to believe him.\n",
      "If I were you, I'd give up.\n"
     ]
    }
   ],
   "source": [
    "gtos = amrlib.load_gtos_model('/kaggle/input/amr-lda-01/models/generate_t5wtense')\n",
    "sents, _ = gtos.generate(graphs, use_tense=True)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMR-LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:35:48.738172Z",
     "iopub.status.busy": "2025-02-20T17:35:48.737798Z",
     "iopub.status.idle": "2025-02-20T17:35:48.742405Z",
     "shell.execute_reply": "2025-02-20T17:35:48.741543Z",
     "shell.execute_reply.started": "2025-02-20T17:35:48.738143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bleu(targets, predictions, smooth=1.0):\n",
    "    \"\"\"Computes BLEU score.\n",
    "    \n",
    "    Args:\n",
    "    targets: list of strings or list of list of strings if multiple references are present.\n",
    "    predictions: list of strings\n",
    "    \n",
    "    Returns:\n",
    "    bleu_score across all targets and predictions\n",
    "    \"\"\"\n",
    "    bleu_score = sacrebleu.sentence_bleu(predictions[0], targets,\n",
    "                                       smooth_method=\"exp\",\n",
    "                                       smooth_value=smooth,\n",
    "                                       lowercase=False,\n",
    "                                       tokenize=\"intl\")\n",
    "    return {\"bleu\": bleu_score.score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:36:40.394581Z",
     "iopub.status.busy": "2025-02-20T17:36:40.394269Z",
     "iopub.status.idle": "2025-02-20T17:36:40.402007Z",
     "shell.execute_reply": "2025-02-20T17:36:40.401026Z",
     "shell.execute_reply.started": "2025-02-20T17:36:40.394560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_conditions_contraposition(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'have-condition-91'  ## this if is working for contraposition law\n",
    "         and len(g.edges(source=inst.source, role=':ARG1')) == 1\n",
    "         and len(g.edges(source=inst.source, role=':ARG2')) == 1):\n",
    "            yield inst.source\n",
    "\n",
    "def swappable_conditions_contraposition_negative_sample_root(g):\n",
    "    for inst in g.instances():\n",
    "        if (len(g.edges(source=inst.source, role=':condition')) == 1):\n",
    "            yield inst.source\n",
    "\n",
    "def swappable_conditions_commutative(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'and'   ## this elif is working for commutative law\n",
    "         and len(g.edges(source=inst.source, role=':op1')) == 1\n",
    "         and len(g.edges(source=inst.source, role=':op2')) == 1):\n",
    "            yield inst.source\n",
    "\n",
    "def swappable_conditions_implication(g):\n",
    "    for inst in g.instances():\n",
    "        if (inst.target == 'or'   ## this elif is working for implication law\n",
    "         and len(g.edges(source=inst.source, role=':op1')) == 1\n",
    "         and len(g.edges(source=inst.source, role=':op2')) == 1):\n",
    "            yield inst.source\n",
    "\n",
    "def quantifier_target_extractor(g):\n",
    "    for inst in g.instances():\n",
    "        if (len(g.edges(source=inst.source, role=':quant')) == 1):\n",
    "            yield inst.source\n",
    "\n",
    "    for inst in g.instances():\n",
    "        if (len(g.edges(source=inst.source, role=':mod')) == 1):\n",
    "            yield  inst.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:37:09.423729Z",
     "iopub.status.busy": "2025-02-20T17:37:09.423411Z",
     "iopub.status.idle": "2025-02-20T17:37:09.429906Z",
     "shell.execute_reply": "2025-02-20T17:37:09.429082Z",
     "shell.execute_reply.started": "2025-02-20T17:37:09.423705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_conditions_contraposition_2(g):\n",
    "    graph = penman.encode(g)\n",
    "    if \":ARG\" in graph and \":condition\" in graph:\n",
    "        start = graph.index(\"(\")\n",
    "        end = graph.index(\":condition\")\n",
    "        # split_new_condition = \":condition \"+ graph[start:end] +\":polarity -)\"\n",
    "        split_new_condition = \":condition \" + graph[start:end]\n",
    "        # split_old_condition = graph[end+len(\":condition \"):len(graph)-2] + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        split_old_condition = graph[end + len(\":condition \"):len(graph) - 2]\n",
    "        pattern = r':degree \\([^)]+\\)'      \n",
    "\n",
    "        if \":polarity -\" not in split_new_condition and \":polarity -\" not in split_old_condition:\n",
    "            split_new_condition = split_new_condition + \":polarity -)\"\n",
    "            split_old_condition = split_old_condition + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        elif \":polarity -\" in split_new_condition and \":polarity -\" in split_old_condition:\n",
    "            split_new_condition = split_new_condition.replace(\":polarity -\",\"\") + \")\"\n",
    "            split_old_condition = split_old_condition.replace(\":polarity -\",\"\") + \"\\n\"\n",
    "            split_new_condition = re.sub(pattern, '', split_new_condition)\n",
    "            split_old_condition = re.sub(pattern, '', split_old_condition)          \n",
    "        elif \":polarity -\" not in split_new_condition and \":polarity -\" in split_old_condition:\n",
    "            split_new_condition = split_new_condition + \":polarity -)\"\n",
    "            split_old_condition = split_old_condition.replace(\":polarity -\",\"\") + \"\\n\"\n",
    "            split_old_condition = re.sub(pattern, '', split_old_condition)          \n",
    "        elif \":polarity -\" in split_new_condition and \":polarity -\" not in split_old_condition:\n",
    "            split_new_condition = split_new_condition.replace(\":polarity -\",\"\") + \")\"\n",
    "            split_new_condition = re.sub(pattern, '', split_new_condition)\n",
    "            split_old_condition = split_old_condition + \"\\n\" +\":polarity -\" + \"\\n\"          \n",
    "\n",
    "        new_contructed_graph = split_old_condition + split_new_condition + \")\"\n",
    "        # decoded_g = penman.decode(new_contructed_graph)\n",
    "        # return decoded_g\n",
    "        return new_contructed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:37:26.029226Z",
     "iopub.status.busy": "2025-02-20T17:37:26.028910Z",
     "iopub.status.idle": "2025-02-20T17:37:26.034964Z",
     "shell.execute_reply": "2025-02-20T17:37:26.034208Z",
     "shell.execute_reply.started": "2025-02-20T17:37:26.029202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_conditions_contraposition_negative_sample(g):\n",
    "    swap_condition = list(swappable_conditions_contraposition_negative_sample_root(g))\n",
    "    if len(swap_condition) > 0:\n",
    "        z0 = swap_condition[0]\n",
    "        z1 = g.edges(source=z0, role=\":condition\")[0].target\n",
    "        if (z0, ':polarity', '-') not in g.triples and (z1, ':polarity', '-') not in g.triples:\n",
    "            g.triples.append((z1, \":polarity\", '-'))\n",
    "        elif (z0, ':polarity', '-') in g.triples and (z1, ':polarity', '-') in g.triples:\n",
    "            g.triples.remove((z1, \":polarity\", '-'))\n",
    "        elif (z0, ':polarity', '-') not in g.triples and (z1, ':polarity', '-') in g.triples:\n",
    "            g.triples.remove((z1, \":polarity\", '-'))\n",
    "        elif (z0, ':polarity', '-') in g.triples and (z1, ':polarity', '-') not in g.triples:\n",
    "            g.triples.append((z1, \":polarity\", '-'))\n",
    "\n",
    "        new_graph = penman.encode(g)\n",
    "        return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:37:41.699612Z",
     "iopub.status.busy": "2025-02-20T17:37:41.699321Z",
     "iopub.status.idle": "2025-02-20T17:37:41.705210Z",
     "shell.execute_reply": "2025-02-20T17:37:41.704419Z",
     "shell.execute_reply.started": "2025-02-20T17:37:41.699592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_conditions_implication_2(g):\n",
    "    g_temp = copy.deepcopy(g)\n",
    "    graph = penman.encode(g_temp)\n",
    "    if \":ARG\" in graph and \":condition\" in graph:\n",
    "        swap_condition = list(swappable_conditions_contraposition_negative_sample_root(g_temp))\n",
    "        if len(swap_condition) > 0:\n",
    "            z0 = swap_condition[0]\n",
    "            z1 = g_temp.edges(source=z0, role=\":condition\")[0].target\n",
    "            if (z1, ':polarity', '-') not in g_temp.triples:\n",
    "                g_temp.triples.append((z1, \":polarity\", '-'))\n",
    "            elif (z1, ':polarity', '-') in g_temp.triples:\n",
    "                g_temp.triples.remove((z1, \":polarity\", '-'))\n",
    "        graph = penman.encode(g_temp)\n",
    "\n",
    "        start = graph.index(\"(\")\n",
    "        end = graph.index(\":condition\")\n",
    "        # split_new_condition = \":condition \"+ graph[start:end] +\":polarity -)\"\n",
    "        split_new_condition = \":op2 \" + graph[start:end] + \")\"\n",
    "        # split_old_condition = graph[end+len(\":condition \"):len(graph)-2] + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        split_old_condition = \":op1 \" + graph[end + len(\":condition \"):len(graph) - 2] + \")\"\n",
    "\n",
    "        new_contructed_graph = \"(root / or \\n\" + split_old_condition + \"\\n\"+split_new_condition + \")\"\n",
    "        # updated_grapg.triples.append(('root', ':op1', z1))\n",
    "        # decoded_g = penman.decode(new_contructed_graph)\n",
    "        # return decoded_g\n",
    "        return new_contructed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:38:15.419925Z",
     "iopub.status.busy": "2025-02-20T17:38:15.419635Z",
     "iopub.status.idle": "2025-02-20T17:38:15.424727Z",
     "shell.execute_reply": "2025-02-20T17:38:15.423789Z",
     "shell.execute_reply.started": "2025-02-20T17:38:15.419902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def swappable_conditions_implication_2_negative_samples_generation(g):\n",
    "    graph = penman.encode(g)\n",
    "    if \":ARG\" in graph and \":condition\" in graph:\n",
    "        start = graph.index(\"(\")\n",
    "        end = graph.index(\":condition\")\n",
    "        # split_new_condition = \":condition \"+ graph[start:end] +\":polarity -)\"\n",
    "        split_new_condition = \":op2 \" + graph[start:end] + \")\"\n",
    "        # split_old_condition = graph[end+len(\":condition \"):len(graph)-2] + \"\\n\" +\":polarity -\" + \"\\n\"\n",
    "        split_old_condition = \":op1 \" + graph[end + len(\":condition \"):len(graph) - 2] + \")\"\n",
    "\n",
    "        new_contructed_graph = \"(root / or \\n\" + split_old_condition + \"\\n\"+split_new_condition + \")\"\n",
    "        # updated_grapg.triples.append(('root', ':op1', z1))\n",
    "        # decoded_g = penman.decode(new_contructed_graph)\n",
    "        # return decoded_g\n",
    "        return new_contructed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:38:35.240878Z",
     "iopub.status.busy": "2025-02-20T17:38:35.240584Z",
     "iopub.status.idle": "2025-02-20T17:38:35.251252Z",
     "shell.execute_reply": "2025-02-20T17:38:35.250332Z",
     "shell.execute_reply.started": "2025-02-20T17:38:35.240857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def contraposition(graphs, sentence_list, logic_word_list):\n",
    "    return_list = []\n",
    "    label_list = []\n",
    "    sentence_and_tag_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        g = penman.decode(graph)\n",
    "        negative_sample_g = copy.deepcopy(g)\n",
    "        if len(list(swappable_conditions_contraposition(g))) != 0:\n",
    "            swap_condition = list(swappable_conditions_contraposition(g))\n",
    "            z0 = swap_condition[0]\n",
    "            z1 = g.edges(source=z0, role=':ARG1')[0].target\n",
    "            z5 = g.edges(source=z0, role=':ARG2')[0].target\n",
    "            g.triples.remove((z0, ':ARG1', z1))  # remove the triples\n",
    "            g.triples.remove((z0, ':ARG2', z5))\n",
    "            g.triples.append((z0, ':ARG1', z5))  # add the replacements\n",
    "            g.triples.append((z0, ':ARG2', z1))\n",
    "            if (z1, ':polarity', '-') not in g.triples and (z5, ':polarity', '-') not in g.triples:\n",
    "                g.triples.append((z1, ':polarity', '-'))  # add polarity -\n",
    "                g.triples.append((z5, ':polarity', '-'))\n",
    "                negative_sample_g.triples.append((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') in g.triples and (z5, ':polarity', '-') in g.triples:\n",
    "                g.triples.remove((z1, ':polarity', '-'))  # add polarity -\n",
    "                g.triples.remove((z5, ':polarity', '-'))\n",
    "                negative_sample_g.triples.remove((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') not in g.triples and (z5, ':polarity', '-') in g.triples:\n",
    "                g.triples.append((z1, ':polarity', '-'))  # add polarity -\n",
    "                g.triples.remove((z5, ':polarity', '-'))\n",
    "                negative_sample_g.triples.remove((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') in g.triples and (z5, ':polarity', '-') not in g.triples:\n",
    "                g.triples.remove((z1, ':polarity', '-'))  # add polarity -\n",
    "                g.triples.append((z5, ':polarity', '-'))\n",
    "                negative_sample_g.triples.append((z5, ':polarity', '-'))\n",
    "            new_graph = penman.encode(g)\n",
    "            return_list.append(new_graph)\n",
    "            label_list.append(1)\n",
    "            sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "\n",
    "            ## append negative samples\n",
    "            negative_sample_graph = penman.encode(negative_sample_g)\n",
    "            return_list.append(negative_sample_graph)\n",
    "            label_list.append(0)\n",
    "            sentence_and_tag_list.append([sentence_list[index],logic_word_list[index]])\n",
    "            # return_list.append(g)\n",
    "        else:\n",
    "            return_result = swappable_conditions_contraposition_2(g)\n",
    "            negative_return_result = swappable_conditions_contraposition_negative_sample(g)\n",
    "            if return_result is not None:\n",
    "                return_list.append(return_result)\n",
    "                label_list.append(1)\n",
    "                sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "            if negative_return_result is not None:\n",
    "                return_list.append(negative_return_result)\n",
    "                label_list.append(0)\n",
    "                sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "    return return_list, label_list, sentence_and_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:38:46.965258Z",
     "iopub.status.busy": "2025-02-20T17:38:46.964898Z",
     "iopub.status.idle": "2025-02-20T17:38:46.973121Z",
     "shell.execute_reply": "2025-02-20T17:38:46.972372Z",
     "shell.execute_reply.started": "2025-02-20T17:38:46.965230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def commutative(graphs, sentence_list, logic_word_list):\n",
    "    return_list = []\n",
    "    label_list = []\n",
    "    sentence_and_tag_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        g = penman.decode(graph)\n",
    "        negative_sample_g = copy.deepcopy(g)\n",
    "        if len(list(swappable_conditions_commutative(g))) != 0:\n",
    "            swap_condition = list(swappable_conditions_commutative(g))\n",
    "            z0 = swap_condition[0]\n",
    "            z1 = g.edges(source=z0, role=':op1')[0].target\n",
    "            z5 = g.edges(source=z0, role=':op2')[0].target\n",
    "            g.triples.remove((z0, ':op1', z1))  # remove the triples\n",
    "            g.triples.remove((z0, ':op2', z5))\n",
    "            g.triples.append((z0, ':op1', z5))  # add the replacements\n",
    "            g.triples.append((z0, ':op2', z1))\n",
    "            new_graph = penman.encode(g)\n",
    "            return_list.append(new_graph)\n",
    "            label_list.append(1)\n",
    "            sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "\n",
    "            if (z1, ':polarity', '-') not in g.triples and (z5, ':polarity', '-') not in g.triples:\n",
    "                negative_sample_g.triples.append((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') in g.triples and (z5, ':polarity', '-') in g.triples:\n",
    "                negative_sample_g.triples.remove((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') not in g.triples and (z5, ':polarity', '-') in g.triples:\n",
    "                negative_sample_g.triples.remove((z5, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') in g.triples and (z5, ':polarity', '-') not in g.triples:\n",
    "                negative_sample_g.triples.append((z5, ':polarity', '-'))\n",
    "\n",
    "            negative_sample_graph = penman.encode(negative_sample_g)\n",
    "            return_list.append(negative_sample_graph)\n",
    "            label_list.append(0)\n",
    "            sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "\n",
    "    return return_list, label_list, sentence_and_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:39:08.556411Z",
     "iopub.status.busy": "2025-02-20T17:39:08.556114Z",
     "iopub.status.idle": "2025-02-20T17:39:08.572305Z",
     "shell.execute_reply": "2025-02-20T17:39:08.571516Z",
     "shell.execute_reply.started": "2025-02-20T17:39:08.556389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def implication(graphs, sentence_list, logic_word_list):\n",
    "    return_list = []\n",
    "    label_list = []\n",
    "    sentence_and_tag_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for graph_index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        g = penman.decode(graph)\n",
    "        negative_sample_g = copy.deepcopy(g)\n",
    "        if len(list(swappable_conditions_implication(g))) != 0:\n",
    "            swap_condition = list(swappable_conditions_implication(g))\n",
    "            z0 = swap_condition[0]\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":instance\":\n",
    "                    g.triples[index] = item[:2] + ('have-condition-91',)\n",
    "                    break\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":op1\":\n",
    "                    g.triples[index] = item[:1] + (':ARG1',) + item[2:3]\n",
    "                    break\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":op2\":\n",
    "                    g.triples[index] = item[:1] + (':ARG2',) + item[2:3]\n",
    "                    break\n",
    "\n",
    "            z1 = g.edges(source=z0, role=':ARG1')[0].target\n",
    "            z5 = g.edges(source=z0, role=':ARG2')[0].target\n",
    "            g.triples.remove((z0, ':ARG1', z1))\n",
    "            g.triples.remove((z0, ':ARG2', z5))\n",
    "            g.triples.append((z0, ':ARG1', z5))\n",
    "            g.triples.append((z0, ':ARG2', z1))\n",
    "            if (z1, ':polarity', '-') not in g.triples:\n",
    "                g.triples.append((z1, ':polarity', '-'))\n",
    "            elif (z1, ':polarity', '-') in g.triples:\n",
    "                g.triples.remove((z1, ':polarity', '-'))\n",
    "\n",
    "            new_graph = penman.encode(g)\n",
    "            return_list.append(new_graph)\n",
    "            label_list.append(1)\n",
    "            sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "\n",
    "            swap_condition_negative_sample = list(swappable_conditions_implication(negative_sample_g))\n",
    "            z0_neg = swap_condition_negative_sample[0]\n",
    "            z1_neg = negative_sample_g.edges(source=z0_neg, role=':op1')[0].target\n",
    "            z5_neg = negative_sample_g.edges(source=z0_neg, role=':op2')[0].target\n",
    "            if (z1_neg, ':polarity', '-') in negative_sample_g.triples:\n",
    "                negative_sample_g.triples.remove((z1_neg, ':polarity', '-'))\n",
    "            elif (z5_neg, ':polarity', '-') in negative_sample_g.triples:\n",
    "                negative_sample_g.triples.remove((z5_neg, ':polarity', '-'))\n",
    "            else:\n",
    "                negative_sample_g.triples.append((z5_neg, ':polarity', '-'))\n",
    "            new_negative_graph = penman.encode(negative_sample_g)\n",
    "            return_list.append(new_negative_graph)\n",
    "            label_list.append(0)\n",
    "            sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "\n",
    "        elif len(list(swappable_conditions_contraposition(g))) != 0:\n",
    "            swap_condition = list(swappable_conditions_contraposition(g))\n",
    "            z0 = swap_condition[0]\n",
    "            z1 = g.edges(source=z0, role=':ARG1')[0].target\n",
    "            z5 = g.edges(source=z0, role=':ARG2')[0].target\n",
    "            g.triples.remove((z0, ':ARG1', z1))  # remove the triples\n",
    "            g.triples.remove((z0, ':ARG2', z5))\n",
    "            g.triples.append((z0, ':ARG1', z5))  # add the replacements\n",
    "            g.triples.append((z0, ':ARG2', z1))\n",
    "            if (z5, ':polarity', '-') not in g.triples:\n",
    "                g.triples.append((z5, ':polarity', '-'))\n",
    "            elif (z5, ':polarity', '-') in g.triples:\n",
    "                g.triples.remove((z5, ':polarity', '-'))\n",
    "\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":instance\":\n",
    "                    g.triples[index] = item[:2] + ('or',)\n",
    "                    break\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":ARG1\":\n",
    "                    g.triples[index] = item[:1] + (':op1',) + item[2:3]\n",
    "                    break\n",
    "            for index, item in enumerate(g.triples):\n",
    "                if item[0] == z0 and item[1] == \":ARG2\":\n",
    "                    g.triples[index] = item[:1] + (':op2',) + item[2:3]\n",
    "                    break\n",
    "            new_graph = penman.encode(g)\n",
    "            return_list.append(new_graph)\n",
    "            label_list.append(1)\n",
    "            sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "\n",
    "            swap_condition_negative_sample = list(swappable_conditions_contraposition(negative_sample_g))\n",
    "            z0_neg = swap_condition_negative_sample[0]\n",
    "            z1_neg = negative_sample_g.edges(source=z0_neg, role=':ARG1')[0].target\n",
    "            z5_neg = negative_sample_g.edges(source=z0_neg, role=':ARG2')[0].target\n",
    "            if (z1_neg, ':polarity', '-') in negative_sample_g.triples:\n",
    "                negative_sample_g.triples.remove((z1_neg, ':polarity', '-'))\n",
    "            elif (z5_neg, ':polarity', '-') in negative_sample_g.triples:\n",
    "                negative_sample_g.triples.remove((z5_neg, ':polarity', '-'))\n",
    "            else:\n",
    "                negative_sample_g.triples.append((z5_neg, ':polarity', '-'))\n",
    "            new_negative_graph = penman.encode(negative_sample_g)\n",
    "            return_list.append(new_negative_graph)\n",
    "            label_list.append(0)\n",
    "            sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "\n",
    "        else:\n",
    "            return_result = swappable_conditions_implication_2(g)\n",
    "            negative_result = swappable_conditions_implication_2_negative_samples_generation(g)\n",
    "            if return_result is not None:\n",
    "                return_list.append(return_result)\n",
    "                label_list.append(1)\n",
    "                sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "            if negative_result is not None:\n",
    "                return_list.append(negative_result)\n",
    "                label_list.append(0)\n",
    "                sentence_and_tag_list.append([sentence_list[graph_index], logic_word_list[graph_index]])\n",
    "    return return_list, label_list, sentence_and_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:42:57.858507Z",
     "iopub.status.busy": "2025-02-20T17:42:57.858160Z",
     "iopub.status.idle": "2025-02-20T17:42:57.868932Z",
     "shell.execute_reply": "2025-02-20T17:42:57.867969Z",
     "shell.execute_reply.started": "2025-02-20T17:42:57.858479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def double_negation(graphs, sentence_list, logic_word_list):\n",
    "    return_list = []\n",
    "    negative_list = []\n",
    "    label_list = []\n",
    "    sentence_and_tag_list = []\n",
    "    return_sents = []\n",
    "    returned_sentence_and_tag_list = []\n",
    "    if graphs is None:\n",
    "        return\n",
    "    for index, graph in enumerate(graphs):\n",
    "        if graph is None:\n",
    "            continue\n",
    "        g = penman.decode(graph)\n",
    "        updated_g = copy.deepcopy(g)\n",
    "        negative_g = copy.deepcopy(g)\n",
    "        if \":polarity -\" not in graph:  ## We only consider the case that the sentence does not have negation.\n",
    "            z0 = updated_g.instances()[0].source\n",
    "            updated_g.triples.append((z0, ':polarity', '-'))\n",
    "            temp_graph = penman.encode(updated_g)\n",
    "            start = temp_graph.index(\"\\n\")\n",
    "            return_list.append(temp_graph[start+1:len(temp_graph)])\n",
    "            sentence_and_tag_list.append([sentence_list[index], logic_word_list[index]])\n",
    "            negative_list.append(penman.encode(negative_g))\n",
    "\n",
    "    if len(return_list) > 0:\n",
    "        gtos = amrlib.load_gtos_model(\"/kaggle/input/amr-lda-01/models/generate_t5wtense\")\n",
    "        sents, _ = gtos.generate(return_list)\n",
    "        punctuation_string = string.punctuation\n",
    "\n",
    "        for idx, sent in enumerate(sents):\n",
    "            temp_sent = copy.deepcopy(sent)\n",
    "            for i in punctuation_string:\n",
    "                temp_sent = temp_sent.replace(i, '')\n",
    "            splited_sent = temp_sent.split()\n",
    "            for stem in splited_sent:\n",
    "                if len(wordnet.synsets(stem)) > 0:\n",
    "                    syn = wordnet.synsets(stem)[0]\n",
    "                    good = wordnet.synset(syn.name())\n",
    "                    antonym = good.lemmas()[0].antonyms()\n",
    "                    if len(antonym) > 0:\n",
    "                        if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n",
    "                            sent = sent.replace(stem,antonym[0].name())\n",
    "                            returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n",
    "                            return_sents.append(sent)\n",
    "                            label_list.append(1)\n",
    "                            break\n",
    "\n",
    "        neg_sents, _ = gtos.generate(negative_list)\n",
    "\n",
    "        for idx, sent in enumerate(neg_sents):\n",
    "            temp_sent = copy.deepcopy(sent)\n",
    "            for i in punctuation_string:\n",
    "                temp_sent = temp_sent.replace(i, '')\n",
    "            splited_sent = temp_sent.split()\n",
    "            for stem in splited_sent:\n",
    "                if len(wordnet.synsets(stem)) > 0:\n",
    "                    syn = wordnet.synsets(stem)[0]\n",
    "                    good = wordnet.synset(syn.name())\n",
    "                    antonym = good.lemmas()[0].antonyms()\n",
    "                    if len(antonym) > 0:\n",
    "                        if wordnet.synsets(antonym[0].name())[0].pos() == 'a':\n",
    "                            sent = sent.replace(stem, antonym[0].name())\n",
    "                            returned_sentence_and_tag_list.append(sentence_and_tag_list[idx])\n",
    "                            return_sents.append(sent)\n",
    "                            label_list.append(0)\n",
    "                            break\n",
    "\n",
    "    return return_sents, label_list, returned_sentence_and_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:41:48.336948Z",
     "iopub.status.busy": "2025-02-20T17:41:48.336653Z",
     "iopub.status.idle": "2025-02-20T17:41:48.431452Z",
     "shell.execute_reply": "2025-02-20T17:41:48.430737Z",
     "shell.execute_reply.started": "2025-02-20T17:41:48.336925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "logic_word_list = []\n",
    "dataframe_list = []\n",
    "dataframe_list_single_sentences = []\n",
    "flag = \"Synthetic\"\n",
    "\n",
    "if flag == \"Synthetic\":\n",
    "    dataframe_synthetic = pd.read_csv(\"/kaggle/input/amr-lda-01/output_result/synthetic_sentences.csv\")\n",
    "    dataframe_list.append(dataframe_synthetic)\n",
    "    dataframe_synthetic_2 = pd.read_csv(\"/kaggle/input/amr-lda-01/output_result/synthetic_single_no_logic_words_sentences.csv\")\n",
    "    dataframe_list_single_sentences.append(dataframe_synthetic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T17:43:24.370692Z",
     "iopub.status.busy": "2025-02-20T17:43:24.370360Z",
     "iopub.status.idle": "2025-02-20T17:43:24.381267Z",
     "shell.execute_reply": "2025-02-20T17:43:24.380492Z",
     "shell.execute_reply.started": "2025-02-20T17:43:24.370665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keywords_list = [flag]\n",
    "data = []\n",
    "df = pd.DataFrame(data, columns=['Origin', 'Original_Sentence', 'Generated_Sentence', 'BLEU_Score', 'Label', 'Tag',\n",
    "                                     'logic_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:07:02.290069Z",
     "iopub.status.busy": "2025-02-20T18:07:02.289712Z",
     "iopub.status.idle": "2025-02-20T18:11:09.216295Z",
     "shell.execute_reply": "2025-02-20T18:11:09.215404Z",
     "shell.execute_reply.started": "2025-02-20T18:07:02.290022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 728/728 [00:00<00:00, 731.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dataframe_list_single_sentences):\n",
    "    for index, row in item.iterrows():\n",
    "        sentence_list.append(row['Sentences'])\n",
    "        logic_word_list.append(row['Logic-words'])\n",
    "\n",
    "    graphs = stog.parse_sents(sentence_list)\n",
    "    double_negation_list, double_negation_label_list, double_negation_sentence_and_tag_list = [], [], []\n",
    "    double_negation_list, double_negation_label_list, double_negation_sentence_and_tag_list = double_negation(graphs, sentence_list, logic_word_list)\n",
    "\n",
    "    ## To convert graphs to sentences\n",
    "    if len(double_negation_list) > 0:\n",
    "        # sents, _ = gtos.generate(double_negation_list)\n",
    "        for sent_id in tqdm(range(len(double_negation_list))):\n",
    "            bleu_score = bleu([double_negation_sentence_and_tag_list[sent_id][0]], [double_negation_list[sent_id]])\n",
    "            df.loc[len(df)] = {'Origin': keywords_list[idx], 'Original_Sentence': double_negation_sentence_and_tag_list[sent_id][0],\n",
    "                               'Generated_Sentence': double_negation_list[sent_id], 'BLEU_Score': bleu_score['bleu'],\n",
    "                               'Label': double_negation_label_list[sent_id], 'Tag': \"Double negation law\",\n",
    "                               'logic_words': double_negation_sentence_and_tag_list[sent_id][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T18:11:32.184298Z",
     "iopub.status.busy": "2025-02-20T18:11:32.183953Z",
     "iopub.status.idle": "2025-02-20T18:35:49.527606Z",
     "shell.execute_reply": "2025-02-20T18:35:49.526607Z",
     "shell.execute_reply.started": "2025-02-20T18:11:32.184273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3466/3466 [00:05<00:00, 592.31it/s]\n",
      "100%|██████████| 3680/3680 [00:05<00:00, 614.41it/s]\n",
      "100%|██████████| 6922/6922 [00:13<00:00, 507.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(dataframe_list):\n",
    "    for index, row in item.iterrows():\n",
    "        sentence_list.append(row['Sentences'])\n",
    "        logic_word_list.append(row['Logic-words'])\n",
    "\n",
    "    graphs = stog.parse_sents(sentence_list)\n",
    "\n",
    "    ## logical equivalence\n",
    "    ## contraposition law\n",
    "    # graphs = [\"# ::snt If you can use a computer, you have keyboarding skills.\\n(z0 / have-condition-91\\n      :ARG1 (z1 / have-03\\n            :ARG0 (z2 / you)\\n            :ARG1 (z3 / skill\\n                  :topic (z4 / keyboard-01)))\\n      :ARG2 (z5 / possible-01\\n            :ARG1 (z6 / use-01\\n                  :ARG0 z2\\n                  :ARG1 (z7 / computer))))\"]\n",
    "\n",
    "    contraposition_list, contraposition_label_list, contraposition_sentence_and_tag_list = [], [], []\n",
    "    commutative_list, commutative_label_list, commutative_sentence_and_tag_list = [], [], []\n",
    "    implication_list, implication_label_list, implication_sentence_and_tag_list = [], [], []\n",
    "    double_negation_list, double_negation_label_list, double_negation_sentence_and_tag_list = [], [], []\n",
    "\n",
    "    contraposition_list, contraposition_label_list, contraposition_sentence_and_tag_list = contraposition(graphs, sentence_list, logic_word_list)\n",
    "    commutative_list, commutative_label_list, commutative_sentence_and_tag_list = commutative(graphs, sentence_list, logic_word_list)\n",
    "    implication_list, implication_label_list, implication_sentence_and_tag_list = implication(graphs, sentence_list, logic_word_list)\n",
    "\n",
    "\n",
    "    ## To convert graphs to sentences\n",
    "    # gtos = amrlib.load_gtos_model(\"./pretrained_models/model_generate_t5wtense-v0_1_0\")\n",
    "    if len(contraposition_list) > 0:\n",
    "        sents, _ = gtos.generate(contraposition_list)\n",
    "        for sent_id in tqdm(range(len(sents))):\n",
    "            bleu_score = bleu([contraposition_sentence_and_tag_list[sent_id][0]], [sents[sent_id]])\n",
    "            df.loc[len(df)] = {'Origin':keywords_list[idx],'Original_Sentence': contraposition_sentence_and_tag_list[sent_id][0], 'Generated_Sentence': sents[sent_id], 'BLEU_Score': bleu_score['bleu'], 'Label': contraposition_label_list[sent_id], 'Tag':\"Contraposition law\", 'logic_words':contraposition_sentence_and_tag_list[sent_id][1]}\n",
    "    if len(commutative_list) > 0:\n",
    "        sents, _ = gtos.generate(commutative_list)\n",
    "        for sent_id in tqdm(range(len(sents))):\n",
    "            bleu_score = bleu([commutative_sentence_and_tag_list[sent_id][0]], [sents[sent_id]])\n",
    "            df.loc[len(df)] = {'Origin':keywords_list[idx],'Original_Sentence': commutative_sentence_and_tag_list[sent_id][0], 'Generated_Sentence': sents[sent_id], 'BLEU_Score': bleu_score['bleu'], 'Label': commutative_label_list[sent_id], 'Tag':\"Commutative law\", 'logic_words':commutative_sentence_and_tag_list[sent_id][1]}\n",
    "    if len(implication_list) > 0:\n",
    "        sents, _ = gtos.generate(implication_list)\n",
    "        for sent_id in tqdm(range(len(sents))):\n",
    "            bleu_score = bleu([implication_sentence_and_tag_list[sent_id][0]], [sents[sent_id]])\n",
    "            df.loc[len(df)] = {'Origin':keywords_list[idx],'Original_Sentence': implication_sentence_and_tag_list[sent_id][0], 'Generated_Sentence': sents[sent_id], 'BLEU_Score': bleu_score['bleu'], 'Label': implication_label_list[sent_id], 'Tag':\"Implication law\", 'logic_words':implication_sentence_and_tag_list[sent_id][1]}\n",
    "\n",
    "    df.to_csv(keywords_list[idx]+\"_xfm_t5wtense_logical_equivalence_list.csv\", index = None, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T19:00:58.431923Z",
     "iopub.status.busy": "2025-02-20T19:00:58.431562Z",
     "iopub.status.idle": "2025-02-20T19:00:58.513983Z",
     "shell.execute_reply": "2025-02-20T19:00:58.513339Z",
     "shell.execute_reply.started": "2025-02-20T19:00:58.431894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"/kaggle/working/Synthetic_xfm_t5wtense_logical_equivalence_list.csv\")\n",
    "\n",
    "df_shuffled = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "total_lines = df_shuffled.shape[0]\n",
    "\n",
    "trainset_index = int(total_lines * 0.8)\n",
    "training_set = df_shuffled.iloc[:trainset_index]\n",
    "validation_set = df_shuffled.iloc[trainset_index:total_lines]\n",
    "\n",
    "training_set.columns=['Origin','sentence1','sentence2','BLEU_Score','label','Tag','logic_words']\n",
    "validation_set.columns=['Origin','sentence1','sentence2','BLEU_Score','label','Tag','logic_words']\n",
    "\n",
    "training_set = training_set.drop(['Origin','BLEU_Score','Tag','logic_words'], axis=1)\n",
    "validation_set = validation_set.drop(['Origin','BLEU_Score','Tag','logic_words'], axis=1)\n",
    "\n",
    "training_set.to_csv(\"Synthetic_xfm_t5wtense_train.csv\",index = None,encoding = 'utf8')\n",
    "validation_set.to_csv(\"Synthetic_xfm_t5wtense_validation.csv\",index = None,encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage-1 finetuning (contrastive learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T06:51:07.564967Z",
     "iopub.status.busy": "2025-02-21T06:51:07.564615Z",
     "iopub.status.idle": "2025-02-21T06:51:25.967377Z",
     "shell.execute_reply": "2025-02-21T06:51:25.966706Z",
     "shell.execute_reply.started": "2025-02-21T06:51:07.564940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from huggingface_hub import Repository\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,  \n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    ")\n",
    "from transformers.utils import check_min_version, get_full_repo_name, send_example_telemetry\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T06:52:23.560345Z",
     "iopub.status.busy": "2025-02-21T06:52:23.559607Z",
     "iopub.status.idle": "2025-02-21T06:52:23.564945Z",
     "shell.execute_reply": "2025-02-21T06:52:23.564053Z",
     "shell.execute_reply.started": "2025-02-21T06:52:23.560320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BERTConfig:\n",
    "    # dataset\n",
    "    data_dir = \"/kaggle/input/amr-lda-01/output_result\"  # Subject for data path: Biology, Law\n",
    "    train_data_file_name = \"Synthetic_xfm_t5wtense_train.csv\"\n",
    "    validate_data_file_name = \"Synthetic_xfm_t5wtense_validation.csv\"\n",
    "    # test_data_file_name = \"synthetic_logical_equivalence_sentence_pair_testset.csv\"\n",
    "\n",
    "    # pretrained model\n",
    "    pretrained_model_name = \"Transformers/bert-base-cased/\"  # pretrained model: BERT, BioBERT, RoBERTa, SBERT\n",
    "\n",
    "    # save model\n",
    "    saved_fig_dir = \"result/figure/\"\n",
    "    saved_model_dir = \"result/saved_models/\"  # save model after fine-tune\n",
    "\n",
    "    # load model\n",
    "    load_model_sub_dir_name = \"epoch_3\"  # for load model from a specific sub dir, e.g: epoch_5\n",
    "    predict_result_dir = \"result/predict/\"\n",
    "\n",
    "    # train + predict parameters\n",
    "    GPU_ID = \"1\"\n",
    "    num_labels = 2  # The number of output labels -- 1 for MSE Loss Regression; other for classification.\n",
    "    batch_size = 16  # for DataLoader (when fine-tuning BERT on a specific task, 16 or 32 is recommended)\n",
    "    epochs = 4  # Number of training epochs (we recommend between 2 and 4)\n",
    "    lr = 5e-5  # Optimizer parameters: learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8  # Optimizer parameters: adam_epsilon  - default is 1e-8.\n",
    "    seed = 2022  # Set the seed value all over the place to make this reproducible.\n",
    "\n",
    "    pct_close = 0.1  # predict correct threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T06:53:25.640871Z",
     "iopub.status.busy": "2025-02-21T06:53:25.640578Z",
     "iopub.status.idle": "2025-02-21T06:53:25.645695Z",
     "shell.execute_reply": "2025-02-21T06:53:25.644968Z",
     "shell.execute_reply.started": "2025-02-21T06:53:25.640851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse(self, kwargs):\n",
    "    '''\n",
    "    user can update the default hyperparamter\n",
    "    '''\n",
    "    for k, v in kwargs.items():\n",
    "        if not hasattr(self, k):\n",
    "            raise Exception('config has No key: {}'.format(k))\n",
    "        setattr(self, k, v)\n",
    "\n",
    "    print('*************************************************')\n",
    "    print('user config:')\n",
    "    for k, v in self.__class__.__dict__.items():\n",
    "        if not k.startswith('__'):\n",
    "            print(\"{} => {}\".format(k, getattr(self, k)))\n",
    "\n",
    "    print('*************************************************')\n",
    "\n",
    "BERTConfig.parse = parse\n",
    "opt = BERTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T06:54:20.041841Z",
     "iopub.status.busy": "2025-02-21T06:54:20.041522Z",
     "iopub.status.idle": "2025-02-21T06:54:20.045812Z",
     "shell.execute_reply": "2025-02-21T06:54:20.044991Z",
     "shell.execute_reply.started": "2025-02-21T06:54:20.041812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.GPU_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T06:55:16.083770Z",
     "iopub.status.busy": "2025-02-21T06:55:16.083479Z",
     "iopub.status.idle": "2025-02-21T06:55:16.088233Z",
     "shell.execute_reply": "2025-02-21T06:55:16.087502Z",
     "shell.execute_reply.started": "2025-02-21T06:55:16.083748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "check_min_version(\"4.22.0.dev0\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6707467,
     "sourceId": 10810468,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
